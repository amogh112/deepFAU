{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amogh/cmu/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affectnet-training.py  face_scripts.pyc  save_features.sh\r\n",
      "affectnet-training.sh  __init__.py\t slurm-3561901.out\r\n",
      "face_scripts.py        __init__.pyc\t slurm-3562661.out\r\n"
     ]
    }
   ],
   "source": [
    "!ls scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading libraries\n",
      "libraries loaded\n"
     ]
    }
   ],
   "source": [
    "import scripts.face_scripts as fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading libraries\n",
      "libraries loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"loading libraries\")\n",
    "import os, sys, random, glob, argparse, math, gc\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import matplotlib\n",
    "# import matplotlib.pyplot as plt #causes segmentation fault, so do not use.\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "import sklearn\n",
    "from sklearn import svm, metrics\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bcolz import carray\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import datetime as dt\n",
    "print(\"libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_model = '/media/amogh/Stuff/CMU/datasets/DISFA_data/models/hpc_12July/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/amogh/Stuff/CMU/datasets/DISFA_data/models/hpc_12July/models/2_FAU1_1/result.sav',\n",
       " '/media/amogh/Stuff/CMU/datasets/DISFA_data/models/hpc_12July/models/2_FAU2_1/result.sav',\n",
       " '/media/amogh/Stuff/CMU/datasets/DISFA_data/models/hpc_12July/models/2_FAU4_1/result.sav',\n",
       " '/media/amogh/Stuff/CMU/datasets/DISFA_data/models/hpc_12July/models/3_FAU1_1/result.sav',\n",
       " '/media/amogh/Stuff/CMU/datasets/DISFA_data/models/hpc_12July/models/3_FAU2_1/result.sav',\n",
       " '/media/amogh/Stuff/CMU/datasets/DISFA_data/models/hpc_12July/models/3_FAU4_1/result.sav']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_model_path = glob.glob (folder_model+'/*/result.sav')\n",
    "list_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model = [[file_model.split('/')[-2], pickle.load(open(file_model,'rb'))] for file_model in list_model_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('in model: thresh', ['2_FAU1_1'])\n",
      "('best estimator is: ', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))\n",
      "('best params are: ', {'kernel': 'linear', 'C': 1.0, 'gamma': 0.001})\n",
      "('best score is: ', 0.72746553552492044)\n",
      "\n",
      "('in model: thresh', ['2_FAU2_1'])\n",
      "('best estimator is: ', SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))\n",
      "('best params are: ', {'kernel': 'linear', 'C': 10.0, 'gamma': 0.001})\n",
      "('best score is: ', 0.78091637010676151)\n",
      "\n",
      "('in model: thresh', ['2_FAU4_1'])\n",
      "('best estimator is: ', SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))\n",
      "('best params are: ', {'kernel': 'linear', 'C': 10.0, 'gamma': 0.001})\n",
      "('best score is: ', 0.77247682350883329)\n",
      "\n",
      "('in model: thresh', ['3_FAU1_1'])\n",
      "('best estimator is: ', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))\n",
      "('best params are: ', {'kernel': 'linear', 'C': 1.0, 'gamma': 0.001})\n",
      "('best score is: ', 0.84473049074818984)\n",
      "\n",
      "('in model: thresh', ['3_FAU2_1'])\n",
      "('best estimator is: ', SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))\n",
      "('best params are: ', {'kernel': 'linear', 'C': 0.5, 'gamma': 0.001})\n",
      "('best score is: ', 0.91110183639399001)\n",
      "\n",
      "('in model: thresh', ['3_FAU4_1'])\n",
      "('best estimator is: ', SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))\n",
      "('best params are: ', {'kernel': 'linear', 'C': 10.0, 'gamma': 0.001})\n",
      "('best score is: ', 0.86143470263641941)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for path_file,model in list_model:\n",
    "    print (\"in model: thresh\",path_file.split('/'))\n",
    "    best_estimator = model.best_estimator_\n",
    "    best_params = model.best_params_\n",
    "    best_score = model.best_score_\n",
    "#     cv_res = model.cv_results_\n",
    "    print (\"best estimator is: \",best_estimator)\n",
    "    print (\"best params are: \",best_params)    \n",
    "    print (\"best score is: \",best_score)\n",
    "#     print (\"cross validation results are: \", cv_res)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_model = dict(list_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2_FAU1_1': GridSearchCV(cv=[(array([4339, 4340, ..., 9428, 9429]), array([   0,    1, ..., 4337, 4338])), (array([   0,    1, ..., 9428, 9429]), array([4339, 4340, ..., 4407, 4408])), (array([   0,    1, ..., 9428, 9429]), array([4409, 4410, ..., 4709, 4710])), (array([   0,    1, ..., 9428, 9429]), array([4711, 4712, ..., 7062, 7063])), (array([   0,    1, ..., 9428, 9429]), array([7064, 7065, ..., 8342, 8343])), (array([   0,    1, ..., 8342, 8343]), array([8344, 8345, ..., 9428, 9429]))],\n",
       "        error_score='raise',\n",
       "        estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       "        fit_params=None, iid=True, n_jobs=28,\n",
       "        param_grid={'kernel': ['linear'], 'C': array([  0.1,   0.5,   1. ,   5. ,  10. ,  50. ]), 'gamma': array([  1.00000e-03,   5.00000e-03,   1.00000e-02,   5.00000e-02,\n",
       "          1.00000e-01,   5.00000e-01,   1.00000e+00,   5.00000e+00])},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "        scoring=None, verbose=2),\n",
       " '2_FAU2_1': GridSearchCV(cv=[(array([1285, 1286, ..., 8990, 8991]), array([   0,    1, ..., 1283, 1284])), (array([   0,    1, ..., 8990, 8991]), array([1285, 1286, ..., 1755, 1756])), (array([   0,    1, ..., 8990, 8991]), array([1757, 1758, ..., 4235, 4236])), (array([   0,    1, ..., 8990, 8991]), array([4237, 4238, ..., 5087, 5088])), (array([   0,    1, ..., 8990, 8991]), array([5089, 5090, ..., 8318, 8319])), (array([   0,    1, ..., 8318, 8319]), array([8320, 8321, ..., 8990, 8991]))],\n",
       "        error_score='raise',\n",
       "        estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       "        fit_params=None, iid=True, n_jobs=28,\n",
       "        param_grid={'kernel': ['linear'], 'C': array([  0.1,   0.5,   1. ,   5. ,  10. ,  50. ]), 'gamma': array([  1.00000e-03,   5.00000e-03,   1.00000e-02,   5.00000e-02,\n",
       "          1.00000e-01,   5.00000e-01,   1.00000e+00,   5.00000e+00])},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "        scoring=None, verbose=2),\n",
       " '2_FAU4_1': GridSearchCV(cv=[(array([ 3767,  3768, ..., 22866, 22867]), array([   0,    1, ..., 3765, 3766])), (array([    0,     1, ..., 22866, 22867]), array([3767, 3768, ..., 7801, 7802])), (array([    0,     1, ..., 22866, 22867]), array([ 7803,  7804, ..., 10425, 10426])), (array([    0,     1, ..., 22866, 22867]), arr...466, 16467])), (array([    0,     1, ..., 16466, 16467]), array([16468, 16469, ..., 22866, 22867]))],\n",
       "        error_score='raise',\n",
       "        estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       "        fit_params=None, iid=True, n_jobs=28,\n",
       "        param_grid={'kernel': ['linear'], 'C': array([  0.1,   0.5,   1. ,   5. ,  10. ,  50. ]), 'gamma': array([  1.00000e-03,   5.00000e-03,   1.00000e-02,   5.00000e-02,\n",
       "          1.00000e-01,   5.00000e-01,   1.00000e+00,   5.00000e+00])},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "        scoring=None, verbose=2),\n",
       " '3_FAU1_1': GridSearchCV(cv=[(array([ 738,  739, ..., 3727, 3728]), array([  0,   1, ..., 736, 737])), (array([   0,    1, ..., 3727, 3728]), array([ 738,  739, ..., 1394, 1395])), (array([   0,    1, ..., 3727, 3728]), array([1396, 1397, ..., 1523, 1524])), (array([   0,    1, ..., 3727, 3728]), array([1525, 1526, ..., 1791, 1792])), (array([   0,    1, ..., 3727, 3728]), array([1793, 1794, ..., 2969, 2970])), (array([   0,    1, ..., 2969, 2970]), array([2971, 2972, ..., 3727, 3728]))],\n",
       "        error_score='raise',\n",
       "        estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       "        fit_params=None, iid=True, n_jobs=28,\n",
       "        param_grid={'kernel': ['linear'], 'C': array([  0.1,   0.5,   1. ,   5. ,  10. ,  50. ]), 'gamma': array([  1.00000e-03,   5.00000e-03,   1.00000e-02,   5.00000e-02,\n",
       "          1.00000e-01,   5.00000e-01,   1.00000e+00,   5.00000e+00])},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "        scoring=None, verbose=2),\n",
       " '3_FAU2_1': GridSearchCV(cv=[(array([ 747,  748, ..., 2394, 2395]), array([  0,   1, ..., 745, 746])), (array([   0,    1, ..., 2394, 2395]), array([ 747,  748, ..., 1026, 1027])), (array([   0,    1, ..., 2394, 2395]), array([1028, 1029, ..., 1922, 1923])), (array([   0,    1, ..., 2394, 2395]), array([1924, 1925, ..., 2058, 2059])), (array([   0,    1, ..., 2058, 2059]), array([2060, 2061, ..., 2394, 2395]))],\n",
       "        error_score='raise',\n",
       "        estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       "        fit_params=None, iid=True, n_jobs=28,\n",
       "        param_grid={'kernel': ['linear'], 'C': array([  0.1,   0.5,   1. ,   5. ,  10. ,  50. ]), 'gamma': array([  1.00000e-03,   5.00000e-03,   1.00000e-02,   5.00000e-02,\n",
       "          1.00000e-01,   5.00000e-01,   1.00000e+00,   5.00000e+00])},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "        scoring=None, verbose=2),\n",
       " '3_FAU4_1': GridSearchCV(cv=[(array([ 1250,  1251, ..., 11415, 11416]), array([   0,    1, ..., 1248, 1249])), (array([    0,     1, ..., 11415, 11416]), array([1250, 1251, ..., 4786, 4787])), (array([    0,     1, ..., 11415, 11416]), array([4788, 4789, ..., 5826, 5827])), (array([    0,     1, ..., 11415, 11416]), array([...211, 10212])), (array([    0,     1, ..., 10211, 10212]), array([10213, 10214, ..., 11415, 11416]))],\n",
       "        error_score='raise',\n",
       "        estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       "        fit_params=None, iid=True, n_jobs=28,\n",
       "        param_grid={'kernel': ['linear'], 'C': array([  0.1,   0.5,   1. ,   5. ,  10. ,  50. ]), 'gamma': array([  1.00000e-03,   5.00000e-03,   1.00000e-02,   5.00000e-02,\n",
       "          1.00000e-01,   5.00000e-01,   1.00000e+00,   5.00000e+00])},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "        scoring=None, verbose=2)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "* Makes sense that the threshold 3 ones are easily separable with a higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions on kids data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(im_path,thresh, cropping_function_name, o=6 ,ppc=(8,8) ,cpb=(4,4), detector=detector, predictor=predictor,  function_dict=fs.function_dict, featuresFunction=fs.getHOGFeatures):\n",
    "    try:\n",
    "        #cropping and aligning images\n",
    "        im_aligned_cropped,landmarkPoints = fs.detectAndaligncrop(im_path, detector, predictor)\n",
    "        cropped_rgb_image = function_dict[cropping_function_name] (im_aligned_cropped, landmarkPoints)\n",
    "        #getting features\n",
    "        fd = featuresFunction(o, ppc, cpb, cropped_rgb_image)\n",
    "        return fd\n",
    "    except: \n",
    "#         print(\"error in file, possibly face not detected in : \", im_path)\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(im_path, thresh, cropping_function_name,dict_model=dict_model , o=6 ,ppc=(8,8) ,cpb=(4,4), detector=detector, predictor=predictor,  function_dict=fs.function_dict, featuresFunction=fs.getHOGFeatures):\n",
    "    model = dict_model['{}_{}'.format(thresh, cropping_function_name)]\n",
    "    fd = get_features(im_path=im_path,thresh=thresh, cropping_function_name=cropping_function_name, o=o ,ppc=ppc ,cpb=cpb, detector=detector, predictor=predictor,  function_dict=function_dict, featuresFunction=featuresFunction)\n",
    "#     print(fd)\n",
    "    if fd is not None:\n",
    "        pred = model.predict([fd])\n",
    "#         print(\"prediction is: \" , pred)\n",
    "        return pred\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred ('/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 092.jpg',3,'FAU1_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For FAU 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_fau_1_2_manual_labels = '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fau_1_2_manual_labels = glob.glob(folder_fau_1_2_manual_labels + \"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 085.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 086.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 087.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 088.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 089.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 090.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 091.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 092.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 093.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 094.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 096.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 097.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 098.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 099.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 100.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 101.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 102.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 103.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 104.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 105.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 107.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 108.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 109.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 110.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 092.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 093.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 094.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 095.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 096.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 097.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 095.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 106.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 098.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 108.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 099.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 100.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 101.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 102.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 103.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 104.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 105.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 106.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 107.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 086.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 087.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 088.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 089.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 090.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 091.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 016.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 017.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 018.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 019.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 020.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 021.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 022.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 023.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 024.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 025.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 026.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 027.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 028.jpg']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fau_1_2_manual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3_FAU2_1', '3_FAU4_1', '2_FAU2_1', '2_FAU1_1', '3_FAU1_1', '2_FAU4_1']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_model_names = dict_model.keys()\n",
    "list_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating\n",
      "('thresh: ', '3', 'FAU2_1')\n",
      "[2, 2, 2, 2, 2, array([1]), array([1]), array([1]), 2, 2, 2, array([1]), array([1]), array([1]), 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), 2, array([0]), array([0]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0])]\n",
      "('positives are:15 out of 62 ', ' and face not detected for 19 ')\n",
      "('accuracy for images in which face is detected is: ', 0.3488372093023256)\n",
      "calculating\n",
      "('thresh: ', '3', 'FAU4_1')\n",
      "[2, 2, 2, 2, 2, array([1]), array([1]), array([1]), 2, 2, 2, array([1]), array([1]), array([1]), 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), 2, array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1])]\n",
      "('positives are:37 out of 62 ', ' and face not detected for 19 ')\n",
      "('accuracy for images in which face is detected is: ', 0.8604651162790697)\n",
      "calculating\n",
      "('thresh: ', '2', 'FAU2_1')\n",
      "[2, 2, 2, 2, 2, array([0]), array([0]), array([0]), 2, 2, 2, array([0]), array([0]), array([1]), 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), 2, array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([1]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0])]\n",
      "('positives are:14 out of 62 ', ' and face not detected for 19 ')\n",
      "('accuracy for images in which face is detected is: ', 0.32558139534883723)\n",
      "calculating\n",
      "('thresh: ', '2', 'FAU1_1')\n",
      "[2, 2, 2, 2, 2, array([1]), array([1]), array([1]), 2, 2, 2, array([1]), array([1]), array([1]), 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), 2, array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1])]\n",
      "('positives are:43 out of 62 ', ' and face not detected for 19 ')\n",
      "('accuracy for images in which face is detected is: ', 1.0)\n",
      "calculating\n",
      "('thresh: ', '3', 'FAU1_1')\n",
      "[2, 2, 2, 2, 2, array([1]), array([1]), array([1]), 2, 2, 2, array([0]), array([1]), array([1]), 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), 2, array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1])]\n",
      "('positives are:41 out of 62 ', ' and face not detected for 19 ')\n",
      "('accuracy for images in which face is detected is: ', 0.9534883720930233)\n",
      "calculating\n",
      "('thresh: ', '2', 'FAU4_1')\n",
      "[2, 2, 2, 2, 2, array([1]), array([1]), array([1]), 2, 2, 2, array([1]), array([1]), array([1]), 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), 2, array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([0]), array([1]), array([0]), array([0]), array([0]), array([1]), array([1]), array([1]), array([0]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1]), array([1])]\n",
      "('positives are:38 out of 62 ', ' and face not detected for 19 ')\n",
      "('accuracy for images in which face is detected is: ', 0.8837209302325582)\n"
     ]
    }
   ],
   "source": [
    "list_target = list_fau_1_2_manual_labels\n",
    "for model in list_model_names:\n",
    "    print(\"calculating\")\n",
    "    mod = dict_model[model]\n",
    "    thresh =  model[0]\n",
    "    crop_fun_name = model[2:]\n",
    "    print (\"thresh: \", thresh, crop_fun_name)\n",
    "    array_results = ([pred(f,thresh,crop_fun_name) for f in list_target])\n",
    "    print(array_results)\n",
    "    print(\"positives are:{} out of {} \".format(array_results.count(1),len(array_results)), \" and face not detected for {} \".format(array_results.count(2)))\n",
    "    print(\"accuracy for images in which face is detected is: \", (array_results.count(1))/float(array_results.count(1)+array_results.count(0)) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,1,2,4,3].count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 085.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 086.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 087.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 088.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 089.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 090.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 091.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 092.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 093.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 094.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 096.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 097.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 098.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 099.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 100.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 101.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 102.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 103.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 104.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 105.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 107.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 108.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 109.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 110.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 092.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 093.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 094.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 095.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 096.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 097.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 095.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_044827_472499497 106.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 098.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 108.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 099.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 100.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 101.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 102.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 103.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 104.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 105.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 106.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_00-male-surprise_20180517_045352_534376196 107.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 086.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 087.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 088.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 089.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 090.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_03-female-delight_20180517_045924_1325910015 091.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 016.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 017.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 018.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 019.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 020.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 021.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 022.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 023.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 024.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 025.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 026.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 027.jpg',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_fau12/VIDEO_08-female-frustration_20180517_045627_985384939 028.jpg']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fau_1_2_manual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
