{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and setting folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, glob, argparse, math, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bcolz import carray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_DISFA_data = \"/media/amogh/Stuff/CMU/datasets/DISFA_data/\"\n",
    "folder_DISFA_FAU = \"/media/amogh/Stuff/CMU/datasets/DISFA_data/ActionUnit_Labels/\"\n",
    "folder_DISFA_FAU_summary = \"DISFA_FAUs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a dictionary with positives and negatives for each subject and frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary in the form: {'SN001':{'positives': [1,2,3],'negatives':[4,5,6,7] }}\n",
    "# ie corresponding to each subject a dictionary which contains list frame nos which are positives and \n",
    "def getDISFAFramesDictionary(folder_DISFA_FAU_summary, fau_no, fau_thresh):\n",
    "    df_fau = pd.read_csv(folder_DISFA_FAU_summary + \"{}/\".format(fau_thresh) + \"FAU{}.csv\".format(fau_no))\n",
    "    df_positives = df_fau.filter(regex=\"^((?!neg).)*$\",axis=1)\n",
    "    df_negatives = df_fau.filter(like=\"neg\",axis=1) \n",
    "    list_subjects = df_positives.columns.values\n",
    "    fau_dict = {}\n",
    "    for subj in list_subjects:\n",
    "        fau_dict[subj] = {'positives':[], 'negatives':[]}\n",
    "        fau_dict[subj]['positives'] = [f for f in df_positives[subj].values if not math.isnan(f)]\n",
    "        fau_dict[subj]['negatives'] = [f for f in df_negatives[\"{}_neg\".format(subj)].values if not math.isnan(f)]\n",
    "    return fau_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test and train folds of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary with keys as fold_0,fold_1,...,test\n",
    "# make sure number of folds exactly divide the train subjects\n",
    "def getTrainTestFolds (fau_dict, no_folds, no_test_subjects):\n",
    "    list_subjects = fau_dict.keys()\n",
    "    no_train_subjects = len(list_subjects) - no_test_subjects\n",
    "    random.shuffle(list_subjects)\n",
    "    test_subjects = list_subjects[-no_test_subjects:]\n",
    "    train_subjects = list_subjects[:-no_test_subjects]\n",
    "    dict_folds = {'test':{}}\n",
    "    # putting train and test subjects in new dictionary\n",
    "    for subj in test_subjects:\n",
    "        dict_folds['test'][subj] = fau_dict[subj]\n",
    "    fold_size = no_train_subjects / no_folds\n",
    "#     fold_size_remainder = no_train_subjects % no_folds\n",
    "    for fold_no in range(no_folds):\n",
    "        fold_subjects = train_subjects[fold_no*fold_size : fold_no*fold_size+fold_size]\n",
    "        dict_folds ['fold_{}'.format(fold_no)]={}\n",
    "        for sub in fold_subjects:\n",
    "            dict_folds ['fold_{}'.format(fold_no)] [sub] = fau_dict [sub]\n",
    "    return dict_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop and save images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for cropping given an image path "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "args={\"shape_predictor\":\"shape_predictor_68_face_landmarks.dat\"}\n",
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(args[\"shape_predictor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityTransform(inPoints, outPoints) :\n",
    "    s60 = math.sin(60*math.pi/180);\n",
    "    c60 = math.cos(60*math.pi/180);  \n",
    "  \n",
    "    inPts = np.copy(inPoints).tolist();\n",
    "    outPts = np.copy(outPoints).tolist();\n",
    "    \n",
    "    xin = c60*(inPts[0][0] - inPts[1][0]) - s60*(inPts[0][1] - inPts[1][1]) + inPts[1][0];\n",
    "    yin = s60*(inPts[0][0] - inPts[1][0]) + c60*(inPts[0][1] - inPts[1][1]) + inPts[1][1];\n",
    "    \n",
    "    inPts.append([np.int(xin), np.int(yin)]);\n",
    "    \n",
    "    xout = c60*(outPts[0][0] - outPts[1][0]) - s60*(outPts[0][1] - outPts[1][1]) + outPts[1][0];\n",
    "    yout = s60*(outPts[0][0] - outPts[1][0]) + c60*(outPts[0][1] - outPts[1][1]) + outPts[1][1];\n",
    "    \n",
    "    outPts.append([np.int(xout), np.int(yout)]);\n",
    "    \n",
    "    tform = cv2.estimateRigidTransform(np.array([inPts]), np.array([outPts]), False);\n",
    "    \n",
    "    return tform;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new function, doesnt write landmarks every single time\n",
    "def detectAndaligncrop(impath, detector, predictor):\n",
    "    image=cv2.imread(impath)\n",
    "    image_float=np.float32(image)/255.0\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 1)\n",
    "    #initialising images and allPoints arrays\n",
    "    allPoints=[]\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        points=[]\n",
    "        for (x,y) in shape:\n",
    "            points.append((x,y))\n",
    "        allPoints.append(points)\n",
    "    images=[image_float]\n",
    "    #computation\n",
    "    w=112\n",
    "    h=112\n",
    "    eyecornerDst = [ (np.int(0.3 * w ), np.int(h / 3)), (np.int(0.7 * w ), np.int(h / 3)) ];\n",
    "    imagesNorm = [];\n",
    "    pointsNorm = [];\n",
    "    #     print allPoints[0]\n",
    "    # Add boundary points for delaunay triangulation\n",
    "    boundaryPts = np.array([(0,0), (w/2,0), (w-1,0), (w-1,h/2), ( w-1, h-1 ), ( w/2, h-1 ), (0, h-1), (0,h/2) ]);\n",
    "    n = len(allPoints[0]);\n",
    "    numImages = len(images)\n",
    "    for i in xrange(0, numImages):\n",
    "        points1 = allPoints[i];\n",
    "        # Corners of the eye in input image\n",
    "        eyecornerSrc  = [ allPoints[i][36], allPoints[i][45] ] ;\n",
    "        # Compute similarity transform\n",
    "        tform = similarityTransform(eyecornerSrc, eyecornerDst);\n",
    "        # Apply similarity transformation\n",
    "        img = cv2.warpAffine(images[i], tform, (w,h));\n",
    "    #         print(\"debug im type shape max mean min \", img.dtype,img.shape,np.max(img),np.mean(img),np.min(img))\n",
    "    #         plt.imshow(img)\n",
    "        # Apply similarity transform on points\n",
    "        points2 = np.reshape(np.array(points1), (68,1,2));        \n",
    "        points = cv2.transform(points2, tform);\n",
    "        points = np.float32(np.reshape(points, (68, 2)));\n",
    "        pointsNorm.append(points);\n",
    "        imagesNorm.append(img);\n",
    "    #     print (pointsNorm[0])\n",
    "    #     plt.imshow(imagesNorm[0]) \n",
    "    # Output image\n",
    "    output=imagesNorm[0]\n",
    "    rgb_image=cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
    "    return rgb_image, pointsNorm[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crop and save function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-4374bf8ba1f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#                         cropped_image = function_dict[cropping_function_name](im_rgb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_dest_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim_rgb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mcropAndSave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetTrainTestFolds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetDISFAFramesDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_DISFA_FAU_summary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder_DISFA_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-301-4374bf8ba1f8>\u001b[0m in \u001b[0;36mcropAndSave\u001b[0;34m(fau_no, thresh, dict_folds, folder_DISFA_data, cropping_function_name, function_dict, boolSave)\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mim_dest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder_dest_image\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                         \u001b[0mim_aligned_cropped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlandmarkPoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetectAndaligncrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                         \u001b[0mim_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_aligned_cropped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#                         cropped_image = function_dict[cropping_function_name](im_rgb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-290-23ed0a96a252>\u001b[0m in \u001b[0;36mdetectAndaligncrop\u001b[0;34m(impath, detector, predictor)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#initialising images and allPoints arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mallPoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def cropAndSave (o ,ppc ,cpb ,fau_no , thresh, dict_folds, folder_DISFA_data, cropping_function_name, function_dict, boolSave=True):\n",
    "    folder_cropped_images = folder_DISFA_data + \"/features/cropped_images/\"\n",
    "    folder_dest = folder_cropped_images +  \"/{}/{}/\".format(thresh,cropping_function_name)\n",
    "    # initialize dlib's face detector (HOG-based) and then create\n",
    "    # the facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    if not os.path.exists(folder_dest):\n",
    "        os.makedirs(folder_dest)\n",
    "    for fold in dict_folds.keys():\n",
    "        for subj in dict_folds[fold]:\n",
    "            for category in dict_folds[fold][subj]:\n",
    "                folder_dest_image = folder_dest + \"{}/{}/{}/\".format(fold,subj,category)\n",
    "                if not os.path.exists(folder_dest_image):\n",
    "                    os.makedirs(folder_dest_image)\n",
    "                for frame in dict_folds[fold][subj][category]:\n",
    "                    im_path = folder_DISFA_data + \"Videos_RightCamera/RightVideo{}/{}.jpeg\".format(subj,int(frame))\n",
    "                    im_dest_path = folder_dest_image + os.path.basename(im_path)\n",
    "                    if os.path.exists(im_path):\n",
    "                        im_aligned_cropped,landmarkPoints = detectAndaligncrop(im_path, detector, predictor)\n",
    "                        im_gray = cv2.cvtColor(im_aligned_cropped,cv2.COLOR_BGR2GRAY)\n",
    "                        cropped__gray_image = function_dict[cropping_function_name](im_gray)\n",
    "                        #calculating hog features\n",
    "                        cv2.imwrite(im_dest_path, cropped_gray_image*255.)\n",
    "# cropAndSave(2, 3, getTrainTestFolds(getDISFAFramesDictionary(folder_DISFA_FAU_summary,2,3),5,2), folder_DISFA_data, 1,2) mmmmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-3319ea1e9eb8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-3319ea1e9eb8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def trainDISFA (fau_no, train_no, fau_thresh, test_subjects_no, boolCalcFeatures=False, boolCrossValidation=True, )\u001b[0m\n\u001b[0m                                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def trainDISFA (fau_no, train_no, fau_thresh, test_subjects_no, boolGetLists=False, boolCalcFeatures=False, boolCrossValidation=True, ):\n",
    "    if boolGetLists:\n",
    "        getDISFALists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
