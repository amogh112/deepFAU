{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and setting folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, glob, argparse, math, gc\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import matplotlib\n",
    "# import matplotlib.pyplot as plt #causes segmentation fault, so do not use.\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "import sklearn\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bcolz import carray\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_DISFA_data = \"/media/amogh/Stuff/CMU/datasets/DISFA_data/\"\n",
    "folder_DISFA_FAU = \"/media/amogh/Stuff/CMU/datasets/DISFA_data/ActionUnit_Labels/\"\n",
    "folder_DISFA_FAU_summary = \"DISFA_FAUs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a dictionary with positives and negatives for each subject and frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This function gives a dictionary in which all positives and negatives are there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary in the form: {'SN001':{'positives': [1,2,3],'negatives':[4,5,6,7] }}\n",
    "# ie corresponding to each subject a dictionary which contains list frame nos which are positives and \n",
    "def getDISFAFramesDictionary(folder_DISFA_FAU_summary, fau_no, fau_thresh):\n",
    "    df_fau = pd.read_csv(folder_DISFA_FAU_summary + \"{}/\".format(fau_thresh) + \"FAU{}.csv\".format(fau_no))\n",
    "    df_positives = df_fau.filter(regex=\"^((?!neg).)*$\",axis=1)\n",
    "    df_negatives = df_fau.filter(like=\"neg\",axis=1) \n",
    "    list_subjects = df_positives.columns.values\n",
    "    fau_dict = {}\n",
    "    for subj in list_subjects:\n",
    "        fau_dict[subj] = {'positives':[], 'negatives':[]}\n",
    "        fau_dict[subj]['positives'] = [f for f in df_positives[subj].values if not math.isnan(f)]\n",
    "        fau_dict[subj]['negatives'] = [f for f in df_negatives[\"{}_neg\".format(subj)].values if not math.isnan(f)]\n",
    "    return fau_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To have number of positives and negatives equal in number, let's have a dictionary in which the positives and the negatives corresponding to each category are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equaliseDictionary(fau_dict):\n",
    "    for subj in fau_dict.keys():\n",
    "        number_positives = len(fau_dict[subj]['positives'])\n",
    "        number_negatives = len(fau_dict[subj]['negatives'])\n",
    "        if number_negatives >= number_positives:\n",
    "            fau_dict[subj]['negatives'] = random.sample(fau_dict[subj]['negatives'], number_positives)\n",
    "        else:\n",
    "            fau_dict[subj]['positives'] = random.sample(fau_dict[subj]['positives'], number_negatives)\n",
    "    return fau_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test and train folds of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary with keys as fold_0,fold_1,...,test\n",
    "# make sure number of folds exactly divide the train subjects\n",
    "def getTrainTestFolds (fau_dict, no_folds, no_test_subjects):\n",
    "    list_subjects = fau_dict.keys()\n",
    "    no_train_subjects = len(list_subjects) - no_test_subjects\n",
    "    random.shuffle(list_subjects)\n",
    "    test_subjects = list_subjects[-no_test_subjects:]\n",
    "    train_subjects = list_subjects[:-no_test_subjects]\n",
    "    dict_folds = {'test':{}}\n",
    "    # putting train and test subjects in new dictionary\n",
    "    for subj in test_subjects:\n",
    "        dict_folds['test'][subj] = fau_dict[subj]\n",
    "    fold_size = no_train_subjects / no_folds\n",
    "#     fold_size_remainder = no_train_subjects % no_folds\n",
    "    for fold_no in range(no_folds):\n",
    "        fold_subjects = train_subjects[fold_no*fold_size : fold_no*fold_size+fold_size]\n",
    "        dict_folds ['fold_{}'.format(fold_no)]={}\n",
    "        for sub in fold_subjects:\n",
    "            dict_folds ['fold_{}'.format(fold_no)] [sub] = fau_dict [sub]\n",
    "    return dict_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop and save images and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for cropping given an image path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityTransform(inPoints, outPoints) :\n",
    "    s60 = math.sin(60*math.pi/180);\n",
    "    c60 = math.cos(60*math.pi/180);  \n",
    "  \n",
    "    inPts = np.copy(inPoints).tolist();\n",
    "    outPts = np.copy(outPoints).tolist();\n",
    "    \n",
    "    xin = c60*(inPts[0][0] - inPts[1][0]) - s60*(inPts[0][1] - inPts[1][1]) + inPts[1][0];\n",
    "    yin = s60*(inPts[0][0] - inPts[1][0]) + c60*(inPts[0][1] - inPts[1][1]) + inPts[1][1];\n",
    "    \n",
    "    inPts.append([np.int(xin), np.int(yin)]);\n",
    "    \n",
    "    xout = c60*(outPts[0][0] - outPts[1][0]) - s60*(outPts[0][1] - outPts[1][1]) + outPts[1][0];\n",
    "    yout = s60*(outPts[0][0] - outPts[1][0]) + c60*(outPts[0][1] - outPts[1][1]) + outPts[1][1];\n",
    "    \n",
    "    outPts.append([np.int(xout), np.int(yout)]);\n",
    "    \n",
    "    tform = cv2.estimateRigidTransform(np.array([inPts]), np.array([outPts]), False);\n",
    "    \n",
    "    return tform;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new function, doesnt write landmarks every single time\n",
    "def detectAndaligncrop(impath, detector, predictor):\n",
    "    image=cv2.imread(impath)\n",
    "    image_float=np.float32(image)/255.0\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 1)\n",
    "    #initialising images and allPoints arrays\n",
    "    allPoints=[]\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        points=[]\n",
    "        for (x,y) in shape:\n",
    "            points.append((x,y))\n",
    "        allPoints.append(points)\n",
    "    images=[image_float]\n",
    "    #computation\n",
    "    w=112\n",
    "    h=112\n",
    "    eyecornerDst = [ (np.int(0.3 * w ), np.int(h / 3)), (np.int(0.7 * w ), np.int(h / 3)) ];\n",
    "    imagesNorm = [];\n",
    "    pointsNorm = [];\n",
    "    #     print allPoints[0]\n",
    "    # Add boundary points for delaunay triangulation\n",
    "    boundaryPts = np.array([(0,0), (w/2,0), (w-1,0), (w-1,h/2), ( w-1, h-1 ), ( w/2, h-1 ), (0, h-1), (0,h/2) ]);\n",
    "    n = len(allPoints[0]);\n",
    "    numImages = len(images)\n",
    "    for i in xrange(0, numImages):\n",
    "        points1 = allPoints[i];\n",
    "        # Corners of the eye in input image\n",
    "        eyecornerSrc  = [ allPoints[i][36], allPoints[i][45] ] ;\n",
    "        # Compute similarity transform\n",
    "        tform = similarityTransform(eyecornerSrc, eyecornerDst);\n",
    "        # Apply similarity transformation\n",
    "        img = cv2.warpAffine(images[i], tform, (w,h));\n",
    "    #         print(\"debug im type shape max mean min \", img.dtype,img.shape,np.max(img),np.mean(img),np.min(img))\n",
    "    #         plt.imshow(img)\n",
    "        # Apply similarity transform on points\n",
    "        points2 = np.reshape(np.array(points1), (68,1,2));        \n",
    "        points = cv2.transform(points2, tform);\n",
    "        points = np.float32(np.reshape(points, (68, 2)));\n",
    "        pointsNorm.append(points);\n",
    "        imagesNorm.append(img);\n",
    "    #     print (pointsNorm[0])\n",
    "    #     plt.imshow(imagesNorm[0]) \n",
    "    # Output image\n",
    "    output=imagesNorm[0]\n",
    "    rgb_image=cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
    "    return rgb_image, pointsNorm[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions for getting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting HOG, given an image path or an image, return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in rgb images and returns the required HOG descriptor array. \n",
    "def getHOGFeatures (orientations, pixels_per_cell, cells_per_block, image):\n",
    "    if isinstance(image, basestring):\n",
    "        im = cv2.cvtColor(cv2.imread(image),cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        im = image\n",
    "    gray_im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) \n",
    "    fd, hog_image = hog(gray_im, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualise=True)\n",
    "#     hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))\n",
    "#     plt.imshow (hog_image_rescaled, cmap = plt.cm.gray)\n",
    "#     print(\"HOG vector dimension: \", fd.shape)\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imageTouse=\"files_may20/1.jpeg\"\n",
    "sample_alignedAndCropped,landmarkPoints=detectAndaligncrop(imageTouse, detector, predictor)\n",
    "plt.imshow(sample_alignedAndCropped)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = getHOGFeatures(6, (8,8), (4,4), sample_alignedAndCropped)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "carray_fd = carray(a, rootdir='/home/amogh/m', mode = 'w')\n",
    "carray_fd.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other ways to get features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing functions and function_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAU4_1(image,landmarks):\n",
    "    cropped_im=image[:38]\n",
    "    return cropped_im\n",
    "\n",
    "def FAU1_1(image,landmarks):\n",
    "    cropped_im=image[:38]\n",
    "    return cropped_im\n",
    "\n",
    "def FAU2_1(image,landmarks):\n",
    "    cropped_im=image[:38]\n",
    "    return cropped_im\n",
    "\n",
    "def FAU5_1(image,landmarkPoints): #includes border\n",
    "    rect_top=int(landmarkPoints[17][1])\n",
    "    rect_bottom=int(landmarkPoints[29][1])\n",
    "    rect_left=int(landmarkPoints[3][0])\n",
    "    rect_right=int(landmarkPoints[12][0])\n",
    "    cropped_im=image[rect_top:rect_bottom,rect_left:rect_right]\n",
    "    border_top, border_bottom, border_left, border_right = [0,32-height,0,64-width]\n",
    "    img_with_border = cv2.copyMakeBorder(cropped_im, border_top, border_bottom, border_left, border_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "    return img_with_border\n",
    "\n",
    "def FAU12right_1(image,landmarkPoints):\n",
    "    rect_top = int(landmarkPoints[34][1])\n",
    "    rect_bottom = int(landmarkPoints[11][1])\n",
    "    rect_left = int(landmarkPoints[34][0])\n",
    "    rect_right = int(landmarkPoints[11][0])\n",
    "    cropped_im = image[rect_top:rect_bottom,rect_left:rect_right]\n",
    "    border_top, border_bottom, border_left, border_right = [0,32-height,0,32-width]\n",
    "    img_with_border = cv2.copyMakeBorder(cropped_im, border_top, border_bottom, border_left, border_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "    return img_with_border\n",
    "\n",
    "def FAU12left_1(image,landmarkPoints):\n",
    "    rect_top = int(landmarkPoints[32][1])\n",
    "    rect_bottom = int(landmarkPoints[5][1])\n",
    "    rect_left = int(landmarkPoints[5][0])\n",
    "    rect_right = int(landmarkPoints[32][0])\n",
    "    cropped_im = image[rect_top:rect_bottom,rect_left:rect_right]\n",
    "    border_top, border_bottom, border_left, border_right = [0,32-height,0,32-width]\n",
    "    img_with_border = cv2.copyMakeBorder(cropped_im, border_top, border_bottom, border_left, border_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "    return img_with_border\n",
    "\n",
    "function_dict={'FAU1_1':FAU1_1,'FAU2_1':FAU2_1,'FAU4_1':FAU4_1,'FAU5_1':FAU5_1, 'FAU12right_1':FAU12right_1, 'FAU12left_1':FAU12left_1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crop and save function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made by keeping in mind that these are the parameters that we need to pass: o, ppc cpb, fau_no, thresh, function used for cropping, folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves images and HOG features given the o,ppc,cpb,fau_no,thresh,dict_folds,cropping_function_name,function_dict in folder_DISFA_data/thresh/cropping_function_name\n",
    "def cropAndSaveImageHOG (o ,ppc ,cpb ,fau_no , thresh, dict_folds, folder_DISFA_data, cropping_function_name, function_dict, featuresFunction, boolSave=True):\n",
    "    folder_cropped_images = folder_DISFA_data + \"/features/cropped_images/\"\n",
    "    folder_dest = folder_cropped_images +  \"/{}/{}/\".format(thresh,cropping_function_name)\n",
    "    folder_features_dest = folder_DISFA_data + \"/features/hog/{}/{}/\".format(thresh,cropping_function_name)\n",
    "    print(\"images go to: \",folder_dest, \"\\n\", \"features go to:\", folder_features_dest)\n",
    "    # initialize dlib's face detector (HOG-based) and then create\n",
    "    # the facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    if not os.path.exists(folder_dest):\n",
    "        os.makedirs(folder_dest)\n",
    "    if not os.path.exists(folder_features_dest):\n",
    "        os.makedirs(folder_features_dest)\n",
    "    for fold in dict_folds.keys():\n",
    "        print (\"inside:\", fold)\n",
    "        for subj in dict_folds[fold]:\n",
    "            print (\"saving subject: \", subj)\n",
    "            for category in dict_folds[fold][subj]:\n",
    "                print(\"Images in this category are : \", len(dict_folds[fold][subj][category]))\n",
    "#                 print (\"inside: \",fold,subj,category)\n",
    "                folder_dest_image = folder_dest + \"{}/{}/{}/\".format(fold,subj,category)\n",
    "                folder_dest_feature = folder_features_dest + \"{}/{}/{}/\".format(fold,subj,category)\n",
    "                if not os.path.exists(folder_dest_image):\n",
    "                    os.makedirs(folder_dest_image)\n",
    "                for frame_no, frame in enumerate(dict_folds[fold][subj][category]):\n",
    "                    im_path = folder_DISFA_data + \"Videos_RightCamera/RightVideo{}/{}.jpeg\".format(subj,int(frame))\n",
    "                    im_basename = os.path.basename(im_path)\n",
    "                    im_dest_path = folder_dest_image + im_basename \n",
    "                    features_path = folder_dest_feature + os.path.splitext(im_basename)[0] \n",
    "                    if os.path.exists(im_path):\n",
    "                        try:\n",
    "                            #cropping and aligning images\n",
    "                            im_aligned_cropped,landmarkPoints = detectAndaligncrop(im_path, detector, predictor)\n",
    "                            cropped_rgb_image = function_dict[cropping_function_name] (im_aligned_cropped, landmarkPoints)\n",
    "                            #saving cropped RGB images in BGR(because opencv uses BGR as default)\n",
    "                            cv2.imwrite(im_dest_path, cv2.cvtColor(cropped_rgb_image,cv2.COLOR_RGB2BGR)*255.)\n",
    "                            #getting features\n",
    "                            fd = featuresFunction(o, ppc, cpb, cropped_rgb_image)\n",
    "                            #saving features\n",
    "                            if not (os.path.exists(features_path)):\n",
    "                                os.makedirs(features_path)\n",
    "                            carray_fd = carray(fd, rootdir=features_path, mode = 'w')\n",
    "                            carray_fd.flush()\n",
    "                        except KeyboardInterrupt:\n",
    "                            break\n",
    "                        except: \n",
    "                            continue\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "               "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cropAndSaveImageHOG(6,(8,8),(4,4),2, 3, getTrainTestFolds(getDISFAFramesDictionary(folder_DISFA_FAU_summary,2,3),5,2), folder_DISFA_data,'FAU2_1',function_dict,getHOGFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final abstract function to crop and save images\n",
    "Inputs are: o, ppc, cpb, fau_no, thresh, cropping_function_name <br>\n",
    "Optional inputs: no_folds=5, no_test_subjects=2, function_dict=function_dict, featuresFunction=getHOGFeatures, folder_DISFA_FAU_summary=folder_DISFA_FAU_summary, folder_DISFA_data=folder_DISFA_data, boolEqualise=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalSaveImagesFeatures(o ,ppc ,cpb ,fau_no , thresh, cropping_function_name, no_folds=5, no_test_subjects=2, function_dict=function_dict, featuresFunction=getHOGFeatures, folder_DISFA_FAU_summary=folder_DISFA_FAU_summary, folder_DISFA_data=folder_DISFA_data, boolEqualise=True):\n",
    "    frames_dict = getDISFAFramesDictionary(folder_DISFA_FAU_summary,fau_no,thresh)\n",
    "    frames_dict = equaliseDictionary(frames_dict)\n",
    "    dict_folds = getTrainTestFolds(frames_dict,no_folds,no_test_subjects)\n",
    "    cropAndSaveImageHOG(o ,ppc ,cpb ,fau_no ,thresh , dict_folds, folder_DISFA_data,cropping_function_name,function_dict,getHOGFeatures)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "finalSaveImagesFeatures (6 ,(8,8) ,(4,4) , 5, 2, 'FAU5_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to do:\n",
    "    - just calculate the features and save them in appropriate folder; save colored image only so that you can use deep learning\n",
    "    - for training; load the features and make X, Y. Then train for different folds, report accuracy for each test fold and show the average in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDISFA (fau_no, train_no, fau_thresh, test_subjects_no, boolGetLists=False, boolCalcFeatures=False, boolCrossValidation=True, ):\n",
    "    if boolGetLists:\n",
    "        getDISFALists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainSVMGridSearchModel helper function\n",
    "Using GridSearchCV model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function to use custom cross validation generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to train once custom iterable, train and the test function have been defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSVMGridSearchModel(X_train, Y_train , custom_fold_iterable, no_jobs=1, kernel_list=['rbf','linear']):\n",
    "    #setup parameter search space\n",
    "    gamma_range = np.outer(np.logspace(-3,0,4),np.array([1,5]))\n",
    "    gamma_range = gamma_range.flatten()\n",
    "    C_range = np.outer(np.logspace(-1,1,3),np.array([1,5]))\n",
    "    C_range = C_range.flatten()\n",
    "    parameters = {'kernel': kernel_list,'C':C_range,'gamma':gamma_range}\n",
    "    svm_clsf = svm.SVC()\n",
    "    grid_clsf = sklearn.model_selection.GridSearchCV(estimator=svm_clsf,param_grid=parameters,n_jobs=no_jobs,verbose=2,cv=custom_fold_iterable)\n",
    "    #train\n",
    "    start_time=dt.datetime.now()\n",
    "    print('Start param searching at {}'.format(str(start_time)))\n",
    "    grid_clsf.fit(X_train,Y_train)\n",
    "    elapsed_time=dt.datetime.now()-start_time\n",
    "    print('Elapsed time, param searching {}'.format(str(elapsed_time)))\n",
    "    sorted(grid_clsf.cv_results_.keys())\n",
    "    return grid_clsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainCustomGridSearch(fau_no, thresh, cropping_function_name ,trainFunction , folder_data=folder_DISFA_data):\n",
    "    \n",
    "    fold_folder_list = glob.glob(folder_data + \"features/hog/{}/{}/*\".format(thresh,cropping_function_name))\n",
    "    \n",
    "    # defining global holders and variables\n",
    "    no_folds = len(fold_folder_list)\n",
    "    features = []\n",
    "    targets = []\n",
    "    fold_label_list = []\n",
    "\n",
    "    #processing for each fold:\n",
    "    for fold_no, fol in enumerate(fold_folder_list):\n",
    "        \n",
    "        #lists specific to fold\n",
    "        list_positive_feature_folders = []\n",
    "        list_negative_feature_folders = []\n",
    "        positive_features = []\n",
    "        negative_features = []\n",
    "        fold_targets = []\n",
    "        fold_train_features = []\n",
    "        \n",
    "        #loading features in lists\n",
    "        list_positive_feature_folders.extend(glob.glob(fol + \"/*/positives/*/\"))\n",
    "        list_negative_feature_folders.extend(glob.glob(fol + \"/*/negatives/*/\"))\n",
    "        print(\"loading positive features for fold: \", fold_no)\n",
    "        for pos_feat_folder in list_positive_feature_folders:\n",
    "            pos_feat = carray(rootdir = pos_feat_folder, mode = 'r')\n",
    "            positive_features.append(pos_feat)\n",
    "        print(\"loading negative features for fold: \", fold_no)\n",
    "        for neg_feat_folder in list_negative_feature_folders:\n",
    "            neg_feat = carray(rootdir = neg_feat_folder, mode = 'r')\n",
    "            negative_features.append(neg_feat)\n",
    "\n",
    "        fold_train_features.extend(positive_features)\n",
    "        fold_train_features.extend(negative_features)\n",
    "        fold_targets.extend([1] * len(positive_features))\n",
    "        fold_targets.extend([0] * len(negative_features))\n",
    "        no_fold_features = len(positive_features) + len(negative_features)\n",
    "        print(\"this fold has these many features: \",no_fold_features)\n",
    "        \n",
    "        #updating global features and targets\n",
    "        features.extend(fold_train_features)\n",
    "        targets.extend(fold_targets)\n",
    "        #updating fold_label_list\n",
    "        fold_label_list.extend([fold_no]*no_fold_features)\n",
    "\n",
    "    #defining the custom cross validation generator over training data\n",
    "    cvIterable= []\n",
    "    for fold_no in range(no_folds):\n",
    "        fold_label_list = np.array(fold_label_list)\n",
    "        train_indices = np.argwhere(fold_label_list != fold_no).flatten()\n",
    "        test_indices = np.argwhere(fold_label_list == fold_no).flatten()\n",
    "        cvIterable.append((train_indices,test_indices))\n",
    "    \n",
    "    classifier_results = trainSVMGridSearchModel(features ,targets, cvIterable ,no_jobs=8 , kernel_list=['linear'])\n",
    "    \n",
    "    return classifier_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loading positive features for fold: ', 0)\n",
      "('loading negative features for fold: ', 0)\n",
      "('this fold has these many features: ', 932)\n",
      "Start param searching at 2018-07-11 23:49:49.999923\n",
      "Fitting 1 folds for each of 48 candidates, totalling 48 fits\n",
      "[CV] kernel=linear, C=0.1, gamma=0.001 ...............................\n",
      "[CV] kernel=linear, C=0.1, gamma=0.005 ...............................\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f77ecba4230, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/amogh/...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f77ecba4230, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/amogh/...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n   1059                 self._events.update(event_pairs)\n   1060                 while self._events:\n   1061                     fd, events = self._events.popitem()\n   1062                     try:\n   1063                         fd_obj, handler_func = self._handlers[fd]\n-> 1064                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n   1065                     except (OSError, IOError) as e:\n   1066                         if errno_from_exception(e) == errno.EPIPE:\n   1067                             # Happens when the client closes the connection\n   1068                             pass\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 7, 12, 3, 49, 22, 515974, tzinfo=tzutc()), u'msg_id': u'dda88c99982d49d8b4decee6b21482fe', u'msg_type': u'execute_request', u'session': u'02e2176620e2430a8c8c0555a709b654', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'dda88c99982d49d8b4decee6b21482fe', 'msg_type': u'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['02e2176620e2430a8c8c0555a709b654']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 7, 12, 3, 49, 22, 515974, tzinfo=tzutc()), u'msg_id': u'dda88c99982d49d8b4decee6b21482fe', u'msg_type': u'execute_request', u'session': u'02e2176620e2430a8c8c0555a709b654', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'dda88c99982d49d8b4decee6b21482fe', 'msg_type': u'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['02e2176620e2430a8c8c0555a709b654'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 7, 12, 3, 49, 22, 515974, tzinfo=tzutc()), u'msg_id': u'dda88c99982d49d8b4decee6b21482fe', u'msg_type': u'execute_request', u'session': u'02e2176620e2430a8c8c0555a709b654', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'dda88c99982d49d8b4decee6b21482fe', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\", store_history=True, silent=False, shell_futures=True)\n   2709                 self.displayhook.exec_result = result\n   2710 \n   2711                 # Execute the user code\n   2712                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2713                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2714                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2715                 \n   2716                 self.last_execution_succeeded = not has_raised\n   2717 \n   2718                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-38-890a178e35e9>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f77a87384d0, executi..._before_exec=None error_in_exec=None result=None>)\n   2819                     return True\n   2820 \n   2821             for i, node in enumerate(to_run_interactive):\n   2822                 mod = ast.Interactive([node])\n   2823                 code = compiler(mod, cell_name, \"single\")\n-> 2824                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7770e4cf30, file \"<ipython-input-38-890a178e35e9>\", line 2>\n        result = <ExecutionResult object at 7f77a87384d0, executi..._before_exec=None error_in_exec=None result=None>\n   2825                     return True\n   2826 \n   2827             # Flush softspace\n   2828             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7770e4cf30, file \"<ipython-input-38-890a178e35e9>\", line 2>, result=<ExecutionResult object at 7f77a87384d0, executi..._before_exec=None error_in_exec=None result=None>)\n   2873         outflag = 1  # happens in more places, so it's easier as default\n   2874         try:\n   2875             try:\n   2876                 self.hooks.pre_run_code_hook()\n   2877                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2878                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7770e4cf30, file \"<ipython-input-38-890a178e35e9>\", line 2>\n        self.user_global_ns = {'FAU12left_1': <function FAU12left_1>, 'FAU12right_1': <function FAU12right_1>, 'FAU1_1': <function FAU1_1>, 'FAU2_1': <function FAU2_1>, 'FAU4_1': <function FAU4_1>, 'FAU5_1': <function FAU5_1>, 'In': ['', u'import os, sys, random, glob, argparse, math, ...m\\nfrom time import sleep\\nimport datetime as dt', u'folder_DISFA_data = \"/media/amogh/Stuff/CMU/da...bels/\"\\nfolder_DISFA_FAU_summary = \"DISFA_FAUs/\"', u'import os, sys, random, glob, argparse, math, ...m\\nfrom time import sleep\\nimport datetime as dt', u'folder_DISFA_data = \"/media/amogh/Stuff/CMU/da...bels/\"\\nfolder_DISFA_FAU_summary = \"DISFA_FAUs/\"', u'# returns a dictionary in the form: {\\'SN001\\'...alues if not math.isnan(f)]\\n    return fau_dict', u\"def equaliseDictionary(fau_dict):\\n    for sub...itives'], number_negatives)\\n    return fau_dict\", u\"# returns a dictionary with keys as fold_0,fol...)] [sub] = fau_dict [sub]\\n    return dict_folds\", u'def similarityTransform(inPoints, outPoints) :...rray([outPts]), False);\\n    \\n    return tform;', u'#new function, doesnt write landmarks every si...OR_BGR2RGB)\\n    return rgb_image, pointsNorm[0]', u'#takes in rgb images and returns the required ...OG vector dimension: \", fd.shape)\\n    return fd', u\"def FAU4_1(image,landmarks):\\n    cropped_im=i...ight_1':FAU12right_1, 'FAU12left_1':FAU12left_1}\", u'#saves images and HOG features given the o,ppc...        continue\\n        break\\n               ', u'def finalSaveImagesFeatures(o ,ppc ,cpb ,fau_n...ping_function_name,function_dict,getHOGFeatures)', u'def trainDISFA (fau_no, train_no, fau_thresh, ... ):\\n    if boolGetLists:\\n        getDISFALists', u\"def trainSVMGridSearchModel(X_train, Y_train ,...d_clsf.cv_results_.keys())\\n    return grid_clsf\", u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,3,'FAU2_1',1)\", u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', ...], 'Out': {35: [], 36: []}, '_': [], '_35': [], ...}\n        self.user_ns = {'FAU12left_1': <function FAU12left_1>, 'FAU12right_1': <function FAU12right_1>, 'FAU1_1': <function FAU1_1>, 'FAU2_1': <function FAU2_1>, 'FAU4_1': <function FAU4_1>, 'FAU5_1': <function FAU5_1>, 'In': ['', u'import os, sys, random, glob, argparse, math, ...m\\nfrom time import sleep\\nimport datetime as dt', u'folder_DISFA_data = \"/media/amogh/Stuff/CMU/da...bels/\"\\nfolder_DISFA_FAU_summary = \"DISFA_FAUs/\"', u'import os, sys, random, glob, argparse, math, ...m\\nfrom time import sleep\\nimport datetime as dt', u'folder_DISFA_data = \"/media/amogh/Stuff/CMU/da...bels/\"\\nfolder_DISFA_FAU_summary = \"DISFA_FAUs/\"', u'# returns a dictionary in the form: {\\'SN001\\'...alues if not math.isnan(f)]\\n    return fau_dict', u\"def equaliseDictionary(fau_dict):\\n    for sub...itives'], number_negatives)\\n    return fau_dict\", u\"# returns a dictionary with keys as fold_0,fol...)] [sub] = fau_dict [sub]\\n    return dict_folds\", u'def similarityTransform(inPoints, outPoints) :...rray([outPts]), False);\\n    \\n    return tform;', u'#new function, doesnt write landmarks every si...OR_BGR2RGB)\\n    return rgb_image, pointsNorm[0]', u'#takes in rgb images and returns the required ...OG vector dimension: \", fd.shape)\\n    return fd', u\"def FAU4_1(image,landmarks):\\n    cropped_im=i...ight_1':FAU12right_1, 'FAU12left_1':FAU12left_1}\", u'#saves images and HOG features given the o,ppc...        continue\\n        break\\n               ', u'def finalSaveImagesFeatures(o ,ppc ,cpb ,fau_n...ping_function_name,function_dict,getHOGFeatures)', u'def trainDISFA (fau_no, train_no, fau_thresh, ... ):\\n    if boolGetLists:\\n        getDISFALists', u\"def trainSVMGridSearchModel(X_train, Y_train ,...d_clsf.cv_results_.keys())\\n    return grid_clsf\", u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,3,'FAU2_1',1)\", u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', ...], 'Out': {35: [], 36: []}, '_': [], '_35': [], ...}\n   2879             finally:\n   2880                 # Reset our crash handler in place\n   2881                 sys.excepthook = old_excepthook\n   2882         except SystemExit as e:\n\n...........................................................................\n/home/amogh/cmu/notebooks/<ipython-input-38-890a178e35e9> in <module>()\n      1 # fau_no, thresh, cropping_function_name ,trainFunction , folder_data=folder_DISFA_data\n----> 2 trainCustomGridSearch(2,2,'FAU2_1',1)\n\n...........................................................................\n/home/amogh/cmu/notebooks/<ipython-input-37-64bc93c801af> in trainCustomGridSearch(fau_no=2, thresh=2, cropping_function_name='FAU2_1', trainFunction=1, folder_data='/media/amogh/Stuff/CMU/datasets/DISFA_data/')\n     50         fold_label_list = np.array(fold_label_list)\n     51         train_indices = np.argwhere(fold_label_list != fold_no).flatten()\n     52         test_indices = np.argwhere(fold_label_list == fold_no).flatten()\n     53         cvIterable.append((train_indices,test_indices))\n     54     \n---> 55     classifier_results = trainSVMGridSearchModel(features ,targets, cvIterable ,no_jobs=8 , kernel_list=['linear'])\n     56     \n     57     return classifier_results \n\n...........................................................................\n/home/amogh/cmu/notebooks/<ipython-input-15-86ff059eef01> in trainSVMGridSearchModel(X_train=[carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...], Y_train=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], custom_fold_iterable=[(array([], dtype=int64), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    923, 924, 925, 926, 927, 928, 929, 930, 931]))], no_jobs=8, kernel_list=['linear'])\n      8     svm_clsf = svm.SVC()\n      9     grid_clsf = sklearn.model_selection.GridSearchCV(estimator=svm_clsf,param_grid=parameters,n_jobs=no_jobs,verbose=2,cv=custom_fold_iterable)\n     10     #train\n     11     start_time=dt.datetime.now()\n     12     print('Start param searching at {}'.format(str(start_time)))\n---> 13     grid_clsf.fit(X_train,Y_train)\n     14     elapsed_time=dt.datetime.now()-start_time\n     15     print('Elapsed time, param searching {}'.format(str(elapsed_time)))\n     16     sorted(grid_clsf.cv_results_.keys())\n     17     return grid_clsf\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=[(array([], dtype=int64), array(...ain_score='warn',\n       scoring=None, verbose=2), X=[carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...], y=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _CVIterableWrapper.split of _CVIte...type=int64), array([  0,   1, ..., 930, 931]))])>\n        X = [carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...]\n        y = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=8), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=8)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Jul 11 23:49:51 2018\nPID: 25951 Python 2.7.14: /home/amogh/anaconda3/envs/detect_face/bin/python\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SVC(C=0.10000000000000001, cache_size=200, class...None, shrinking=True,\n  tol=0.001, verbose=False), [carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], {'score': <function _passthrough_scorer>}, array([], dtype=int64), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    923, 924, 925, 926, 927, 928, 929, 930, 931]), 2, {'C': 0.10000000000000001, 'gamma': 0.001, 'kernel': 'linear'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (SVC(C=0.10000000000000001, cache_size=200, class...None, shrinking=True,\n  tol=0.001, verbose=False), [carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], {'score': <function _passthrough_scorer>}, array([], dtype=int64), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    923, 924, 925, 926, 927, 928, 929, 930, 931]), 2, {'C': 0.10000000000000001, 'gamma': 0.001, 'kernel': 'linear'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=SVC(C=0.10000000000000001, cache_size=200, class...None, shrinking=True,\n  tol=0.001, verbose=False), X=[carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...], y=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], scorer={'score': <function _passthrough_scorer>}, train=array([], dtype=int64), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    923, 924, 925, 926, 927, 928, 929, 930, 931]), verbose=2, parameters={'C': 0.10000000000000001, 'gamma': 0.001, 'kernel': 'linear'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method SVC.fit of SVC(C=0.100000000000000...one, shrinking=True,\n  tol=0.001, verbose=False)>\n        X_train = []\n        y_train = []\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/svm/base.py in fit(self=SVC(C=0.10000000000000001, cache_size=200, class...None, shrinking=True,\n  tol=0.001, verbose=False), X=[], y=[], sample_weight=None)\n    144         sparse = sp.isspmatrix(X)\n    145         if sparse and self.kernel == \"precomputed\":\n    146             raise TypeError(\"Sparse precomputed kernels are not supported.\")\n    147         self._sparse = sparse and not callable(self.kernel)\n    148 \n--> 149         X, y = check_X_y(X, y, dtype=np.float64, order='C', accept_sparse='csr')\n        X = []\n        y = []\n    150         y = self._validate_targets(y)\n    151 \n    152         sample_weight = np.asarray([]\n    153                                    if sample_weight is None\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/utils/validation.py in check_X_y(X=[], y=[], accept_sparse='csr', dtype=<type 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    568     y_converted : object\n    569         The converted and validated y.\n    570     \"\"\"\n    571     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    572                     ensure_2d, allow_nd, ensure_min_samples,\n--> 573                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    574     if multi_output:\n    575         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    576                         dtype=None)\n    577     else:\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/utils/validation.py in check_array(array=array([], dtype=float64), accept_sparse='csr', dtype=<type 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    436             if array.ndim == 1:\n    437                 raise ValueError(\n    438                     \"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\n    439                     \"Reshape your data either using array.reshape(-1, 1) if \"\n    440                     \"your data has a single feature or array.reshape(1, -1) \"\n--> 441                     \"if it contains a single sample.\".format(array))\n        array = array([], dtype=float64)\n    442             array = np.atleast_2d(array)\n    443             # To ensure that array flags are maintained\n    444             array = np.array(array, dtype=dtype, order=order, copy=copy)\n    445 \n\nValueError: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-890a178e35e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fau_no, thresh, cropping_function_name ,trainFunction , folder_data=folder_DISFA_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainCustomGridSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FAU2_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-64bc93c801af>\u001b[0m in \u001b[0;36mtrainCustomGridSearch\u001b[0;34m(fau_no, thresh, cropping_function_name, trainFunction, folder_data)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mcvIterable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mclassifier_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainSVMGridSearchModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcvIterable\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mno_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mkernel_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclassifier_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-86ff059eef01>\u001b[0m in \u001b[0;36mtrainSVMGridSearchModel\u001b[0;34m(X_train, Y_train, custom_fold_iterable, no_jobs, kernel_list)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstart_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start param searching at {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mgrid_clsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0melapsed_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Elapsed time, param searching {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f77ecba4230, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/amogh/...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f77ecba4230, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/amogh/...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n   1059                 self._events.update(event_pairs)\n   1060                 while self._events:\n   1061                     fd, events = self._events.popitem()\n   1062                     try:\n   1063                         fd_obj, handler_func = self._handlers[fd]\n-> 1064                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n   1065                     except (OSError, IOError) as e:\n   1066                         if errno_from_exception(e) == errno.EPIPE:\n   1067                             # Happens when the client closes the connection\n   1068                             pass\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 7, 12, 3, 49, 22, 515974, tzinfo=tzutc()), u'msg_id': u'dda88c99982d49d8b4decee6b21482fe', u'msg_type': u'execute_request', u'session': u'02e2176620e2430a8c8c0555a709b654', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'dda88c99982d49d8b4decee6b21482fe', 'msg_type': u'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['02e2176620e2430a8c8c0555a709b654']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 7, 12, 3, 49, 22, 515974, tzinfo=tzutc()), u'msg_id': u'dda88c99982d49d8b4decee6b21482fe', u'msg_type': u'execute_request', u'session': u'02e2176620e2430a8c8c0555a709b654', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'dda88c99982d49d8b4decee6b21482fe', 'msg_type': u'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['02e2176620e2430a8c8c0555a709b654'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 7, 12, 3, 49, 22, 515974, tzinfo=tzutc()), u'msg_id': u'dda88c99982d49d8b4decee6b21482fe', u'msg_type': u'execute_request', u'session': u'02e2176620e2430a8c8c0555a709b654', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'dda88c99982d49d8b4decee6b21482fe', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,2,'FAU2_1',1)\", store_history=True, silent=False, shell_futures=True)\n   2709                 self.displayhook.exec_result = result\n   2710 \n   2711                 # Execute the user code\n   2712                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2713                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2714                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2715                 \n   2716                 self.last_execution_succeeded = not has_raised\n   2717 \n   2718                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-38-890a178e35e9>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f77a87384d0, executi..._before_exec=None error_in_exec=None result=None>)\n   2819                     return True\n   2820 \n   2821             for i, node in enumerate(to_run_interactive):\n   2822                 mod = ast.Interactive([node])\n   2823                 code = compiler(mod, cell_name, \"single\")\n-> 2824                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7770e4cf30, file \"<ipython-input-38-890a178e35e9>\", line 2>\n        result = <ExecutionResult object at 7f77a87384d0, executi..._before_exec=None error_in_exec=None result=None>\n   2825                     return True\n   2826 \n   2827             # Flush softspace\n   2828             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7770e4cf30, file \"<ipython-input-38-890a178e35e9>\", line 2>, result=<ExecutionResult object at 7f77a87384d0, executi..._before_exec=None error_in_exec=None result=None>)\n   2873         outflag = 1  # happens in more places, so it's easier as default\n   2874         try:\n   2875             try:\n   2876                 self.hooks.pre_run_code_hook()\n   2877                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2878                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7770e4cf30, file \"<ipython-input-38-890a178e35e9>\", line 2>\n        self.user_global_ns = {'FAU12left_1': <function FAU12left_1>, 'FAU12right_1': <function FAU12right_1>, 'FAU1_1': <function FAU1_1>, 'FAU2_1': <function FAU2_1>, 'FAU4_1': <function FAU4_1>, 'FAU5_1': <function FAU5_1>, 'In': ['', u'import os, sys, random, glob, argparse, math, ...m\\nfrom time import sleep\\nimport datetime as dt', u'folder_DISFA_data = \"/media/amogh/Stuff/CMU/da...bels/\"\\nfolder_DISFA_FAU_summary = \"DISFA_FAUs/\"', u'import os, sys, random, glob, argparse, math, ...m\\nfrom time import sleep\\nimport datetime as dt', u'folder_DISFA_data = \"/media/amogh/Stuff/CMU/da...bels/\"\\nfolder_DISFA_FAU_summary = \"DISFA_FAUs/\"', u'# returns a dictionary in the form: {\\'SN001\\'...alues if not math.isnan(f)]\\n    return fau_dict', u\"def equaliseDictionary(fau_dict):\\n    for sub...itives'], number_negatives)\\n    return fau_dict\", u\"# returns a dictionary with keys as fold_0,fol...)] [sub] = fau_dict [sub]\\n    return dict_folds\", u'def similarityTransform(inPoints, outPoints) :...rray([outPts]), False);\\n    \\n    return tform;', u'#new function, doesnt write landmarks every si...OR_BGR2RGB)\\n    return rgb_image, pointsNorm[0]', u'#takes in rgb images and returns the required ...OG vector dimension: \", fd.shape)\\n    return fd', u\"def FAU4_1(image,landmarks):\\n    cropped_im=i...ight_1':FAU12right_1, 'FAU12left_1':FAU12left_1}\", u'#saves images and HOG features given the o,ppc...        continue\\n        break\\n               ', u'def finalSaveImagesFeatures(o ,ppc ,cpb ,fau_n...ping_function_name,function_dict,getHOGFeatures)', u'def trainDISFA (fau_no, train_no, fau_thresh, ... ):\\n    if boolGetLists:\\n        getDISFALists', u\"def trainSVMGridSearchModel(X_train, Y_train ,...d_clsf.cv_results_.keys())\\n    return grid_clsf\", u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,3,'FAU2_1',1)\", u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', ...], 'Out': {35: [], 36: []}, '_': [], '_35': [], ...}\n        self.user_ns = {'FAU12left_1': <function FAU12left_1>, 'FAU12right_1': <function FAU12right_1>, 'FAU1_1': <function FAU1_1>, 'FAU2_1': <function FAU2_1>, 'FAU4_1': <function FAU4_1>, 'FAU5_1': <function FAU5_1>, 'In': ['', u'import os, sys, random, glob, argparse, math, ...m\\nfrom time import sleep\\nimport datetime as dt', u'folder_DISFA_data = \"/media/amogh/Stuff/CMU/da...bels/\"\\nfolder_DISFA_FAU_summary = \"DISFA_FAUs/\"', u'import os, sys, random, glob, argparse, math, ...m\\nfrom time import sleep\\nimport datetime as dt', u'folder_DISFA_data = \"/media/amogh/Stuff/CMU/da...bels/\"\\nfolder_DISFA_FAU_summary = \"DISFA_FAUs/\"', u'# returns a dictionary in the form: {\\'SN001\\'...alues if not math.isnan(f)]\\n    return fau_dict', u\"def equaliseDictionary(fau_dict):\\n    for sub...itives'], number_negatives)\\n    return fau_dict\", u\"# returns a dictionary with keys as fold_0,fol...)] [sub] = fau_dict [sub]\\n    return dict_folds\", u'def similarityTransform(inPoints, outPoints) :...rray([outPts]), False);\\n    \\n    return tform;', u'#new function, doesnt write landmarks every si...OR_BGR2RGB)\\n    return rgb_image, pointsNorm[0]', u'#takes in rgb images and returns the required ...OG vector dimension: \", fd.shape)\\n    return fd', u\"def FAU4_1(image,landmarks):\\n    cropped_im=i...ight_1':FAU12right_1, 'FAU12left_1':FAU12left_1}\", u'#saves images and HOG features given the o,ppc...        continue\\n        break\\n               ', u'def finalSaveImagesFeatures(o ,ppc ,cpb ,fau_n...ping_function_name,function_dict,getHOGFeatures)', u'def trainDISFA (fau_no, train_no, fau_thresh, ... ):\\n    if boolGetLists:\\n        getDISFALists', u\"def trainSVMGridSearchModel(X_train, Y_train ,...d_clsf.cv_results_.keys())\\n    return grid_clsf\", u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', u\"# fau_no, thresh, cropping_function_name ,trai...ISFA_data\\ntrainCustomGridSearch(2,3,'FAU2_1',1)\", u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', u'def trainCustomGridSearch(fau_no, thresh, crop...linear\\'])\\n    \\n    return classifier_results ', ...], 'Out': {35: [], 36: []}, '_': [], '_35': [], ...}\n   2879             finally:\n   2880                 # Reset our crash handler in place\n   2881                 sys.excepthook = old_excepthook\n   2882         except SystemExit as e:\n\n...........................................................................\n/home/amogh/cmu/notebooks/<ipython-input-38-890a178e35e9> in <module>()\n      1 # fau_no, thresh, cropping_function_name ,trainFunction , folder_data=folder_DISFA_data\n----> 2 trainCustomGridSearch(2,2,'FAU2_1',1)\n\n...........................................................................\n/home/amogh/cmu/notebooks/<ipython-input-37-64bc93c801af> in trainCustomGridSearch(fau_no=2, thresh=2, cropping_function_name='FAU2_1', trainFunction=1, folder_data='/media/amogh/Stuff/CMU/datasets/DISFA_data/')\n     50         fold_label_list = np.array(fold_label_list)\n     51         train_indices = np.argwhere(fold_label_list != fold_no).flatten()\n     52         test_indices = np.argwhere(fold_label_list == fold_no).flatten()\n     53         cvIterable.append((train_indices,test_indices))\n     54     \n---> 55     classifier_results = trainSVMGridSearchModel(features ,targets, cvIterable ,no_jobs=8 , kernel_list=['linear'])\n     56     \n     57     return classifier_results \n\n...........................................................................\n/home/amogh/cmu/notebooks/<ipython-input-15-86ff059eef01> in trainSVMGridSearchModel(X_train=[carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...], Y_train=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], custom_fold_iterable=[(array([], dtype=int64), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    923, 924, 925, 926, 927, 928, 929, 930, 931]))], no_jobs=8, kernel_list=['linear'])\n      8     svm_clsf = svm.SVC()\n      9     grid_clsf = sklearn.model_selection.GridSearchCV(estimator=svm_clsf,param_grid=parameters,n_jobs=no_jobs,verbose=2,cv=custom_fold_iterable)\n     10     #train\n     11     start_time=dt.datetime.now()\n     12     print('Start param searching at {}'.format(str(start_time)))\n---> 13     grid_clsf.fit(X_train,Y_train)\n     14     elapsed_time=dt.datetime.now()-start_time\n     15     print('Elapsed time, param searching {}'.format(str(elapsed_time)))\n     16     sorted(grid_clsf.cv_results_.keys())\n     17     return grid_clsf\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=[(array([], dtype=int64), array(...ain_score='warn',\n       scoring=None, verbose=2), X=[carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...], y=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _CVIterableWrapper.split of _CVIte...type=int64), array([  0,   1, ..., 930, 931]))])>\n        X = [carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...]\n        y = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=8), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=8)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Jul 11 23:49:51 2018\nPID: 25951 Python 2.7.14: /home/amogh/anaconda3/envs/detect_face/bin/python\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SVC(C=0.10000000000000001, cache_size=200, class...None, shrinking=True,\n  tol=0.001, verbose=False), [carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], {'score': <function _passthrough_scorer>}, array([], dtype=int64), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    923, 924, 925, 926, 927, 928, 929, 930, 931]), 2, {'C': 0.10000000000000001, 'gamma': 0.001, 'kernel': 'linear'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (SVC(C=0.10000000000000001, cache_size=200, class...None, shrinking=True,\n  tol=0.001, verbose=False), [carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], {'score': <function _passthrough_scorer>}, array([], dtype=int64), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    923, 924, 925, 926, 927, 928, 929, 930, 931]), 2, {'C': 0.10000000000000001, 'gamma': 0.001, 'kernel': 'linear'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=SVC(C=0.10000000000000001, cache_size=200, class...None, shrinking=True,\n  tol=0.001, verbose=False), X=[carray((1056,), float64)\n  nbytes := 8.25 KB; cb...041148 ...,  0.00063747  0.00084958\n  0.00051429], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...130151 ...,  0.00073493  0.00052662\n  0.00144238], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...123354 ...,  0.00059332  0.00069583\n  0.00135934], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...038018 ...,  0.00106586  0.00092449\n  0.00039537], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064448 ...,  0.00102378  0.00081641\n  0.00096158], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...133935 ...,  0.00170715  0.00053485\n  0.00160029], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...064283 ...,  0.00096664  0.00051625\n  0.00070959], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0656   ...,  0.0011142   0.00090065\n  0.00154924], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...049393 ...,  0.00091812  0.00098575\n  0.00043395], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...058226 ...,  0.00095758  0.00085687\n  0.00156611], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...031591 ...,  0.00081878  0.00069827\n  0.00098539], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076745 ...,  0.00062709  0.00063264\n  0.00064999], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...076409 ...,  0.00039848  0.00076023\n  0.00100945], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...077749 ...,  0.00045832  0.00084814\n  0.00154909], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...051313 ...,  0.00073664  0.00131863\n  0.00144696], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...054399 ...,  0.00094244  0.00066189\n  0.00083661], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...069815 ...,  0.00089293  0.00076847\n  0.00087228], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...126848 ...,  0.00082049  0.00092523\n  0.00130659], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...119506 ...,  0.00062648  0.00144535\n  0.00061701], carray((1056,), float64)\n  nbytes := 8.25 KB; cb...0086471 ...,  0.00114205  0.0007094\n  0.00140986], ...], y=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], scorer={'score': <function _passthrough_scorer>}, train=array([], dtype=int64), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    923, 924, 925, 926, 927, 928, 929, 930, 931]), verbose=2, parameters={'C': 0.10000000000000001, 'gamma': 0.001, 'kernel': 'linear'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method SVC.fit of SVC(C=0.100000000000000...one, shrinking=True,\n  tol=0.001, verbose=False)>\n        X_train = []\n        y_train = []\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/svm/base.py in fit(self=SVC(C=0.10000000000000001, cache_size=200, class...None, shrinking=True,\n  tol=0.001, verbose=False), X=[], y=[], sample_weight=None)\n    144         sparse = sp.isspmatrix(X)\n    145         if sparse and self.kernel == \"precomputed\":\n    146             raise TypeError(\"Sparse precomputed kernels are not supported.\")\n    147         self._sparse = sparse and not callable(self.kernel)\n    148 \n--> 149         X, y = check_X_y(X, y, dtype=np.float64, order='C', accept_sparse='csr')\n        X = []\n        y = []\n    150         y = self._validate_targets(y)\n    151 \n    152         sample_weight = np.asarray([]\n    153                                    if sample_weight is None\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/utils/validation.py in check_X_y(X=[], y=[], accept_sparse='csr', dtype=<type 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    568     y_converted : object\n    569         The converted and validated y.\n    570     \"\"\"\n    571     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    572                     ensure_2d, allow_nd, ensure_min_samples,\n--> 573                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    574     if multi_output:\n    575         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    576                         dtype=None)\n    577     else:\n\n...........................................................................\n/home/amogh/anaconda3/envs/detect_face/lib/python2.7/site-packages/sklearn/utils/validation.py in check_array(array=array([], dtype=float64), accept_sparse='csr', dtype=<type 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    436             if array.ndim == 1:\n    437                 raise ValueError(\n    438                     \"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\n    439                     \"Reshape your data either using array.reshape(-1, 1) if \"\n    440                     \"your data has a single feature or array.reshape(1, -1) \"\n--> 441                     \"if it contains a single sample.\".format(array))\n        array = array([], dtype=float64)\n    442             array = np.atleast_2d(array)\n    443             # To ensure that array flags are maintained\n    444             array = np.array(array, dtype=dtype, order=order, copy=copy)\n    445 \n\nValueError: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# fau_no, thresh, cropping_function_name ,trainFunction , folder_data=folder_DISFA_data\n",
    "trainCustomGridSearch(2,2,'FAU2_1',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example functions to save and crop images; execute to process train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "finalSaveImagesFeatures (6 ,(8,8) ,(4,4) ,12 , 2, 'FAU12left_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rough functions and ideas(not useful now)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gamma_range = np.outer(np.logspace(-3,0,4),np.array([1,5]))\n",
    "gamma_range = gamma_range.flatten()\n",
    "C_range = np.outer(np.logspace(-1,1,3),np.array([1,5]))\n",
    "C_range = C_range.flatten()\n",
    "parameters = {'kernel': ['linear'],'C':C_range,'gamma':gamma_range}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for g in sklearn.model_selection.ParameterGrid(parameters):\n",
    "    print (g)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def trainSVMGridSearchModel(X_train, Y_train, X_test, Y_test, no_jobs=4, kernel_list=['linear']):\n",
    "    #setup parameter search space\n",
    "    gamma_range = np.outer(np.logspace(-3,0,4),np.array([1,5]))\n",
    "    gamma_range = gamma_range.flatten()\n",
    "    C_range = np.outer(np.logspace(-1,1,3),np.array([1,5]))\n",
    "    C_range = C_range.flatten()\n",
    "    parameters = {'kernel': kernel_list,'C':C_range,'gamma':gamma_range}\n",
    "    for g in sklearn.model_selection.ParameterGrid(parameters):\n",
    "            svm_clsf = svm.SVC(        )\n",
    "    svm_clsf = svm.SVC()\n",
    "    grid_clsf = sklearn.model_selection.GridSearchCV(estimator=svm_clsf,param_grid=parameters,n_jobs=no_jobs,verbose=2, cv=[(slice(None), slice(None))])\n",
    "    #train\n",
    "    start_time=dt.datetime.now()\n",
    "    print('Start param searching at {}'.format(str(start_time)))\n",
    "    grid_clsf.fit(X_train,Y_train)\n",
    "    elapsed_time=dt.datetime.now()-start_time\n",
    "    print('Elapsed time, param searching {}'.format(str(elapsed_time)))\n",
    "    sorted(grid_clsf.cv_results_.keys())\n",
    "    return grid_clsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Train Function for manual fold approach(not useful now)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TO BE ABLE TO TAKE IN OTHER DATASETS ALSO, SET THE FOLDER DATA ACCORDINGLY IN THE CORRESPONDING FUNCTION TO THE DATASET\n",
    "#ideally loading folds also should've been a function.\n",
    "#trainFunction as an argument allows changing choice of function for choosing the model\n",
    "def train(fau_no, thresh, cropping_function_name,trainFunction, folder_data):\n",
    "    fold_folder_list = glob.glob(folder_data + \"features/hog/{}/{}/*\".format(thresh, cropping_function_name))\n",
    "    no_folds = len(fold_folder_list)\n",
    "    for fold_no in range(no_folds):\n",
    "        print(\"In fold number\", fold_no)\n",
    "        #do fold_no times training by testing on the folder corresponding to fold_no\n",
    "        train_folds_folder_list = fold_folder_list[:fold_no] + fold_folder_list[fold_no+1:]\n",
    "        list_positive_feature_folders = []\n",
    "        list_negative_feature_folders = []\n",
    "        positive_features = []\n",
    "        negative_features = []\n",
    "        # populate the list_positive_feature_folders and list_negative_feature_folders\n",
    "        for fol in train_folds_folder_list:\n",
    "            list_positive_feature_folders.extend(glob.glob(fol + \"/*/positives/*/\"))\n",
    "            list_negative_feature_folders.extend(glob.glob(fol + \"/*/negatives/*/\"))\n",
    "        # populate the positive_features and negative_features array\n",
    "        print(\"loading positive features\")\n",
    "        for pos_feat_folder in list_positive_feature_folders:\n",
    "            pos_feat = carray(rootdir = pos_feat_folder, mode = 'r')\n",
    "            positive_features.append(pos_feat)\n",
    "        print(\"loading negative features\")\n",
    "        for neg_feat_folder in list_negative_feature_folders:\n",
    "            neg_feat = carray(rootdir = neg_feat_folder, mode = 'r')\n",
    "            negative_features.append(neg_feat)\n",
    "        positive_features = np.array(positive_features)\n",
    "        negative_features = np.array(negative_features)\n",
    "        print(\"shape of positive features array is: \", (positive_features).shape)\n",
    "        print(\"shape of negative features array is: \", (negative_features).shape)\n",
    "        train_array_X = np.concatenate((positive_features,negative_features))\n",
    "        target_positives = np.ones(positive_features.shape[0])\n",
    "        target_negatives = np.zeros(negative_features.shape[0])\n",
    "        targets_Y = np.append(target_positives, target_negatives)\n",
    "        # training data and labels loaded.\n",
    "\n",
    "        #loading test data\n",
    "        test_folder = fold_folder_list[fold_no]\n",
    "        list_positive_test_folder = glob.glob(test_folder + \"/*/positives/*/\")\n",
    "        list_negative_test_folder = glob.glob(test_folder + \"/*/negatives/*/\")\n",
    "        positive_test_features = []\n",
    "        negative_test_features = []\n",
    "        for pos_feat_folder in list_positive_test_folder:\n",
    "        pos_feat = carray(rootdir = pos_feat_folder, mode = 'r')\n",
    "        positive_test_features.append(pos_feat)\n",
    "        for neg_feat_folder in list_negative_test_folder:\n",
    "            neg_feat = carray(rootdir = neg_feat_folder, mode = 'r')\n",
    "            negative_test_features.append(neg_feat)\n",
    "        positive_test_features = np.array(positive_test_features)\n",
    "        negative_test_features = np.array(negative_test_features)\n",
    "        test_array_X = np.concatenate((positive_test_features,negative_test_features))\n",
    "        test_array_Y = np.append(np.ones(positive_test_features.shape[0]), np.zeros(negative_test_features.shape[0]))\n",
    "        print(\"shape of test array X: \", np.array(test_array_X).shape)\n",
    "        print(\"shape of test array Y: \", np.array(test_array_Y).shape)\n",
    "    \n",
    "        # training for this fold\n",
    "        results = {}\n",
    "        trainFunction(train_array_X, train_targets_Y, test_array_X, test_array_Y)\n",
    "        classificationResult = trainModel(train_array_X, targets_Y, no_jobs, kernel_list = ['linear'])\n",
    "        best_classifier = grid_clsf.best_estimator_\n",
    "        best_params=grid_clsf.best_params_\n",
    "        scores=grid_clsf.cv_results_['mean_test_score'].reshape(2,len(C_range),len(gamma_range))\n",
    "        print(\"scores are: \", scores)\n",
    "        print(\"best classifier is:\", \"\\n\", classifier)\n",
    "        print(\"best parameters are: \", \"\\n\", best_params)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fold_folder_list = glob.glob(folder_DISFA_data + \"features/hog/{}/{}/*\".format(3,'FAU2_1'))\n",
    "no_folds = len(fold_folder_list)\n",
    "for fold_no in range(no_folds):\n",
    "    print(\"In fold number\", fold_no)\n",
    "    #do fold_no times training by testing on the folder corresponding to fold_no\n",
    "    train_folds_folder_list = fold_folder_list[:fold_no] + fold_folder_list[fold_no+1:]\n",
    "    list_positive_feature_folders = []\n",
    "    list_negative_feature_folders = []\n",
    "    positive_features = []\n",
    "    negative_features = []\n",
    "    # populate the list_positive_feature_folders and list_negative_feature_folders\n",
    "    for fol in train_folds_folder_list:\n",
    "        list_positive_feature_folders.extend(glob.glob(fol + \"/*/positives/*/\"))\n",
    "        list_negative_feature_folders.extend(glob.glob(fol + \"/*/negatives/*/\"))\n",
    "    # populate the positive_features and negative_features array\n",
    "    print(\"loading positive features\")\n",
    "    for pos_feat_folder in list_positive_feature_folders:\n",
    "        pos_feat = carray(rootdir = pos_feat_folder, mode = 'r')\n",
    "        positive_features.append(pos_feat)\n",
    "    print(\"loading negative features\")\n",
    "    for neg_feat_folder in list_negative_feature_folders:\n",
    "        neg_feat = carray(rootdir = neg_feat_folder, mode = 'r')\n",
    "        negative_features.append(neg_feat)\n",
    "    positive_features = np.array(positive_features)\n",
    "    negative_features = np.array(negative_features)\n",
    "    print(\"shape of np positive arrays is: \", (positive_features).shape)\n",
    "    print(\"shape of np negative arrays is: \", (negative_features).shape)\n",
    "    train_array_X = np.concatenate((positive_features,negative_features))\n",
    "    train_targets_Y = np.append(np.ones(positive_features.shape[0]), np.zeros(negative_features.shape[0]))\n",
    "    #loading test data\n",
    "    test_folder = fold_folder_list[fold_no]\n",
    "    list_positive_test_folder = glob.glob(test_folder + \"/*/positives/*/\")\n",
    "    list_negative_test_folder = glob.glob(test_folder + \"/*/negatives/*/\")\n",
    "    positive_test_features = []\n",
    "    negative_test_features = []\n",
    "    for pos_feat_folder in list_positive_test_folder:\n",
    "        pos_feat = carray(rootdir = pos_feat_folder, mode = 'r')\n",
    "        positive_test_features.append(pos_feat)\n",
    "    for neg_feat_folder in list_negative_test_folder:\n",
    "        neg_feat = carray(rootdir = neg_feat_folder, mode = 'r')\n",
    "        negative_test_features.append(neg_feat)\n",
    "    positive_test_features = np.array(positive_test_features)\n",
    "    negative_test_features = np.array(negative_test_features)\n",
    "    test_array_X = np.concatenate((positive_test_features,negative_test_features))\n",
    "    test_array_Y = np.append(np.ones(positive_test_features.shape[0]), np.zeros(negative_test_features.shape[0]))\n",
    "    print(\"shape of test array X: \", np.array(test_array_X).shape)\n",
    "    print(\"shape of test array Y: \", np.array(test_array_Y).shape)\n",
    "#     positives = []\n",
    "#     for fold_folder in train_folder_list:\n",
    "#         array_posi=carray(rootdir=dir_features_hog_1_fau4_1+'positives/',mode='r')\n",
    "#         print(fold_foder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
