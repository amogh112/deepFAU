{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and setting folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, glob, argparse, math, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bcolz import carray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_DISFA_data = \"/media/amogh/Stuff/CMU/datasets/DISFA_data/\"\n",
    "folder_DISFA_FAU = \"/media/amogh/Stuff/CMU/datasets/DISFA_data/ActionUnit_Labels/\"\n",
    "folder_DISFA_FAU_summary = \"DISFA_FAUs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a dictionary with positives and negatives for each subject and frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary in the form: {'SN001':{'positives': [1,2,3],'negatives':[4,5,6,7] }}\n",
    "# ie corresponding to each subject a dictionary which contains list frame nos which are positives and \n",
    "def getDISFAFramesDictionary(folder_DISFA_FAU_summary, fau_no, fau_thresh):\n",
    "    df_fau = pd.read_csv(folder_DISFA_FAU_summary + \"{}/\".format(fau_thresh) + \"FAU{}.csv\".format(fau_no))\n",
    "    df_positives = df_fau.filter(regex=\"^((?!neg).)*$\",axis=1)\n",
    "    df_negatives = df_fau.filter(like=\"neg\",axis=1) \n",
    "    list_subjects = df_positives.columns.values\n",
    "    fau_dict = {}\n",
    "    for subj in list_subjects:\n",
    "        fau_dict[subj] = {'positives':[], 'negatives':[]}\n",
    "        fau_dict[subj]['positives'] = [f for f in df_positives[subj].values if not math.isnan(f)]\n",
    "        fau_dict[subj]['negatives'] = [f for f in df_negatives[\"{}_neg\".format(subj)].values if not math.isnan(f)]\n",
    "    return fau_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test and train folds of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary with keys as fold_0,fold_1,...,test\n",
    "# make sure number of folds exactly divide the train subjects\n",
    "def getTrainTestFolds (fau_dict, no_folds, no_test_subjects):\n",
    "    list_subjects = fau_dict.keys()\n",
    "    no_train_subjects = len(list_subjects) - no_test_subjects\n",
    "    random.shuffle(list_subjects)\n",
    "    test_subjects = list_subjects[-no_test_subjects:]\n",
    "    train_subjects = list_subjects[:-no_test_subjects]\n",
    "    dict_folds = {'test':{}}\n",
    "    # putting train and test subjects in new dictionary\n",
    "    for subj in test_subjects:\n",
    "        dict_folds['test'][subj] = fau_dict[subj]\n",
    "    fold_size = no_train_subjects / no_folds\n",
    "#     fold_size_remainder = no_train_subjects % no_folds\n",
    "    for fold_no in range(no_folds):\n",
    "        fold_subjects = train_subjects[fold_no*fold_size : fold_no*fold_size+fold_size]\n",
    "        dict_folds ['fold_{}'.format(fold_no)]={}\n",
    "        for sub in fold_subjects:\n",
    "            dict_folds ['fold_{}'.format(fold_no)] [sub] = fau_dict [sub]\n",
    "    return dict_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop and save images and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for cropping given an image path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarityTransform(inPoints, outPoints) :\n",
    "    s60 = math.sin(60*math.pi/180);\n",
    "    c60 = math.cos(60*math.pi/180);  \n",
    "  \n",
    "    inPts = np.copy(inPoints).tolist();\n",
    "    outPts = np.copy(outPoints).tolist();\n",
    "    \n",
    "    xin = c60*(inPts[0][0] - inPts[1][0]) - s60*(inPts[0][1] - inPts[1][1]) + inPts[1][0];\n",
    "    yin = s60*(inPts[0][0] - inPts[1][0]) + c60*(inPts[0][1] - inPts[1][1]) + inPts[1][1];\n",
    "    \n",
    "    inPts.append([np.int(xin), np.int(yin)]);\n",
    "    \n",
    "    xout = c60*(outPts[0][0] - outPts[1][0]) - s60*(outPts[0][1] - outPts[1][1]) + outPts[1][0];\n",
    "    yout = s60*(outPts[0][0] - outPts[1][0]) + c60*(outPts[0][1] - outPts[1][1]) + outPts[1][1];\n",
    "    \n",
    "    outPts.append([np.int(xout), np.int(yout)]);\n",
    "    \n",
    "    tform = cv2.estimateRigidTransform(np.array([inPts]), np.array([outPts]), False);\n",
    "    \n",
    "    return tform;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new function, doesnt write landmarks every single time\n",
    "def detectAndaligncrop(impath, detector, predictor):\n",
    "    image=cv2.imread(impath)\n",
    "    image_float=np.float32(image)/255.0\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 1)\n",
    "    #initialising images and allPoints arrays\n",
    "    allPoints=[]\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        points=[]\n",
    "        for (x,y) in shape:\n",
    "            points.append((x,y))\n",
    "        allPoints.append(points)\n",
    "    images=[image_float]\n",
    "    #computation\n",
    "    w=112\n",
    "    h=112\n",
    "    eyecornerDst = [ (np.int(0.3 * w ), np.int(h / 3)), (np.int(0.7 * w ), np.int(h / 3)) ];\n",
    "    imagesNorm = [];\n",
    "    pointsNorm = [];\n",
    "    #     print allPoints[0]\n",
    "    # Add boundary points for delaunay triangulation\n",
    "    boundaryPts = np.array([(0,0), (w/2,0), (w-1,0), (w-1,h/2), ( w-1, h-1 ), ( w/2, h-1 ), (0, h-1), (0,h/2) ]);\n",
    "    n = len(allPoints[0]);\n",
    "    numImages = len(images)\n",
    "    for i in xrange(0, numImages):\n",
    "        points1 = allPoints[i];\n",
    "        # Corners of the eye in input image\n",
    "        eyecornerSrc  = [ allPoints[i][36], allPoints[i][45] ] ;\n",
    "        # Compute similarity transform\n",
    "        tform = similarityTransform(eyecornerSrc, eyecornerDst);\n",
    "        # Apply similarity transformation\n",
    "        img = cv2.warpAffine(images[i], tform, (w,h));\n",
    "    #         print(\"debug im type shape max mean min \", img.dtype,img.shape,np.max(img),np.mean(img),np.min(img))\n",
    "    #         plt.imshow(img)\n",
    "        # Apply similarity transform on points\n",
    "        points2 = np.reshape(np.array(points1), (68,1,2));        \n",
    "        points = cv2.transform(points2, tform);\n",
    "        points = np.float32(np.reshape(points, (68, 2)));\n",
    "        pointsNorm.append(points);\n",
    "        imagesNorm.append(img);\n",
    "    #     print (pointsNorm[0])\n",
    "    #     plt.imshow(imagesNorm[0]) \n",
    "    # Output image\n",
    "    output=imagesNorm[0]\n",
    "    rgb_image=cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
    "    return rgb_image, pointsNorm[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions for getting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting HOG, given an image path or an image, return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in rgb images and returns the required HOG descriptor array. \n",
    "def getHOGFeatures (orientations, pixels_per_cell, cells_per_block, image):\n",
    "    if isinstance(image, basestring):\n",
    "        im = cv2.cvtColor(cv2.imread(image),cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        im = image\n",
    "    gray_im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) \n",
    "    fd, hog_image = hog(gray_im, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualise=True)\n",
    "#     hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))\n",
    "#     plt.imshow (hog_image_rescaled, cmap = plt.cm.gray)\n",
    "#     print(\"HOG vector dimension: \", fd.shape)\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imageTouse=\"files_may20/1.jpeg\"\n",
    "sample_alignedAndCropped,landmarkPoints=detectAndaligncrop(imageTouse, detector, predictor)\n",
    "plt.imshow(sample_alignedAndCropped)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = getHOGFeatures(6, (8,8), (4,4), sample_alignedAndCropped)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "carray_fd = carray(a, rootdir='/home/amogh/m', mode = 'w')\n",
    "carray_fd.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other ways to get features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing functions and function_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAU4_1(image,landmarks):\n",
    "    cropped_im=image[:38]\n",
    "    return cropped_im\n",
    "\n",
    "def FAU1_1(image,landmarks):\n",
    "    cropped_im=image[:38]\n",
    "    return cropped_im\n",
    "\n",
    "def FAU2_1(image,landmarks):\n",
    "    cropped_im=image[:38]\n",
    "    return cropped_im\n",
    "\n",
    "def FAU5_1(image,landmarkPoints): #includes border\n",
    "    rect_top=int(landmarkPoints[17][1])\n",
    "    rect_bottom=int(landmarkPoints[29][1])\n",
    "    rect_left=int(landmarkPoints[3][0])\n",
    "    rect_right=int(landmarkPoints[12][0])\n",
    "    cropped_im=image[rect_top:rect_bottom,rect_left:rect_right]\n",
    "    border_top, border_bottom, border_left, border_right = [0,32-height,0,64-width]\n",
    "    img_with_border = cv2.copyMakeBorder(cropped_im, border_top, border_bottom, border_left, border_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "    return img_with_border\n",
    "\n",
    "def FAU12right_1(image,landmarkPoints):\n",
    "    rect_top = int(landmarkPoints[34][1])\n",
    "    rect_bottom = int(landmarkPoints[11][1])\n",
    "    rect_left = int(landmarkPoints[34][0])\n",
    "    rect_right = int(landmarkPoints[11][0])\n",
    "    cropped_im = image[rect_top:rect_bottom,rect_left:rect_right]\n",
    "    border_top, border_bottom, border_left, border_right = [0,32-height,0,32-width]\n",
    "    img_with_border = cv2.copyMakeBorder(cropped_im, border_top, border_bottom, border_left, border_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "    return img_with_border\n",
    "\n",
    "def FAU12left_1(image,landmarkPoints):\n",
    "    rect_top = int(landmarkPoints[32][1])\n",
    "    rect_bottom = int(landmarkPoints[5][1])\n",
    "    rect_left = int(landmarkPoints[5][0])\n",
    "    rect_right = int(landmarkPoints[32][0])\n",
    "    cropped_im = image[rect_top:rect_bottom,rect_left:rect_right]\n",
    "    border_top, border_bottom, border_left, border_right = [0,32-height,0,32-width]\n",
    "    img_with_border = cv2.copyMakeBorder(cropped_im, border_top, border_bottom, border_left, border_right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "    return img_with_border\n",
    "\n",
    "function_dict={'FAU1_1':FAU1_1,'FAU2_1':FAU2_1,'FAU4_1':FAU4_1,'FAU5_1':FAU5_1, 'FAU12right_1':FAU12right_1, 'FAU12left_1':FAU12left_1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crop and save function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves images and HOG features\n",
    "def cropAndSaveImageHOG (o ,ppc ,cpb ,fau_no , thresh, dict_folds, folder_DISFA_data, cropping_function_name, function_dict, featuresFunction, boolSave=True):\n",
    "    folder_cropped_images = folder_DISFA_data + \"/features/cropped_images/\"\n",
    "    folder_dest = folder_cropped_images +  \"/{}/{}/\".format(thresh,cropping_function_name)\n",
    "    folder_features_dest = folder_DISFA_data + \"/features/hog/{}/{}/\".format(thresh,cropping_function_name)\n",
    "    # initialize dlib's face detector (HOG-based) and then create\n",
    "    # the facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    if not os.path.exists(folder_dest):\n",
    "        os.makedirs(folder_dest)\n",
    "    if not os.path.exists(folder_features_dest):\n",
    "        os.makedirs(folder_features_dest)\n",
    "    for fold in dict_folds.keys():\n",
    "        print (\"inside:\", fold)\n",
    "        for subj in dict_folds[fold]:\n",
    "            for category in dict_folds[fold][subj]:\n",
    "                print (\"inside: \",fold,subj,category)\n",
    "                folder_dest_image = folder_dest + \"{}/{}/{}/\".format(fold,subj,category)\n",
    "                folder_dest_feature = folder_features_dest + \"{}/{}/{}/\".format(fold,subj,category)\n",
    "                if not os.path.exists(folder_dest_image):\n",
    "                    os.makedirs(folder_dest_image)\n",
    "                for frame_no, frame in enumerate(dict_folds[fold][subj][category]):\n",
    "                    im_path = folder_DISFA_data + \"Videos_RightCamera/RightVideo{}/{}.jpeg\".format(subj,int(frame))\n",
    "                    im_basename = os.path.basename(im_path)\n",
    "                    im_dest_path = folder_dest_image + im_basename \n",
    "                    features_path = folder_dest_feature + os.path.splitext(im_basename)[0] \n",
    "                    if os.path.exists(im_path):\n",
    "                        try:\n",
    "                            #cropping and aligning images\n",
    "                            im_aligned_cropped,landmarkPoints = detectAndaligncrop(im_path, detector, predictor)\n",
    "                            cropped_rgb_image = function_dict[cropping_function_name] (im_aligned_cropped, landmarkPoints)\n",
    "                            #saving cropped RGB images in BGR(because opencv uses BGR as default)\n",
    "                            cv2.imwrite(im_dest_path, cv2.cvtColor(cropped_rgb_image,cv2.COLOR_RGB2BGR)*255.)\n",
    "                            #getting features\n",
    "                            fd = featuresFunction(o, ppc, cpb, cropped_rgb_image)\n",
    "                            #saving features\n",
    "                            print(\"writing in: \", features_path)\n",
    "                            if not (os.path.exists(features_path)):\n",
    "                                os.makedirs(features_path)\n",
    "                            carray_fd = carray(fd, rootdir=features_path, mode = 'w')\n",
    "                            carray_fd.flush()\n",
    "                            if frame_no%100 == 0:\n",
    "                                print(\"frames processed: \", frame_no)\n",
    "                        except KeyboardInterrupt:\n",
    "                            break\n",
    "                        except: \n",
    "                            continue\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('inside:', 'fold_4')\n",
      "('inside: ', 'fold_4', 'SN030', 'positives')\n",
      "('inside: ', 'fold_4', 'SN030', 'negatives')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/1')\n",
      "('frames processed: ', 0)\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/2')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/3')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/5')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/6')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/7')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/9')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/10')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/11')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/12')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/13')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/14')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/15')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/16')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/17')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/18')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/19')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/20')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/21')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/22')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/23')\n",
      "('writing in: ', '/media/amogh/Stuff/CMU/datasets/DISFA_data//features/hog/3/FAU2_1/fold_4/SN030/negatives/24')\n"
     ]
    }
   ],
   "source": [
    "cropAndSaveImageHOG(6,(8,8),(4,4),2, 3, getTrainTestFolds(getDISFAFramesDictionary(folder_DISFA_FAU_summary,2,3),5,2), folder_DISFA_data,'FAU2_1',function_dict,getHOGFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to do:\n",
    "    - just calculate the features and save them in appropriate folder; save colored image only so that you can use deep learning\n",
    "    - for training; load the features and make X, Y. Then train for different folds, report accuracy for each test fold and show the average in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def trainDISFA (fau_no, train_no, fau_thresh, test_subjects_no, boolGetLists=False, boolCalcFeatures=False, boolCrossValidation=True, ):\n",
    "    if boolGetLists:\n",
    "        getDISFALists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
